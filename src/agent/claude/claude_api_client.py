"""
Simple Claude API Client

Uses team context generated by team_context_command as system prompts
and user input as user prompts to interact with Claude API.
"""

import json
import time
from datetime import datetime
from typing import Dict, Optional, Any

try:
    import anthropic
    HAS_ANTHROPIC = True
except ImportError:
    HAS_ANTHROPIC = False
    print("Anthropic library not available. Please install: pip install anthropic")

import sys
from pathlib import Path

# Add project root to path for imports
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

# Now import using absolute paths from project root
from src.agent.env_config import get_env_config
from src.commands.team_context_command import TeamContextCommand


class ClaudeAPIClient:
    """Simple Claude API client with team context integration"""
    
    def __init__(self, api_key: Optional[str] = None, model: str = "claude-sonnet-4-20250514"):
        """
        Initialize Claude API client
        
        Args:
            api_key: Anthropic API key (if None, loads from environment)
            model: Claude model to use
        """
        if not HAS_ANTHROPIC:
            raise ImportError("Anthropic library required. Install with: pip install anthropic")
        
        # Get API key from environment if not provided
        if api_key is None:
            env_config = get_env_config()
            api_key = env_config.anthropic_api_key
            
        if not api_key:
            raise ValueError("Anthropic API key is required. Set ANTHROPIC_API_KEY environment variable or pass api_key parameter.")
        
        self.client = anthropic.Anthropic(api_key=api_key)
        self.model = model
        self.team_context_command = TeamContextCommand()
        
    def generate_team_context_system_prompt(
        self,
        team_name: str,
        user_message: str = None,
        mode: str = "hybrid",
        stages: Optional[str] = None,
        memory_types: str = "all",
        project_scope: Optional[str] = None,
        memory_importance: int = 2,
        max_memory_items: int = 50,
        tags_filter: Optional[str] = None
    ) -> str:
        """
        Generate system prompt using team context
        
        Args:
            team_name: Team name
            user_message: User message for intelligent memory selection
            mode: Generation mode ('memory_only', 'framework_only', 'hybrid')
            stages: Framework stages (comma-separated or 'all')
            memory_types: Memory types ('declarative', 'procedural', 'episodic', 'all')
            project_scope: Project scope filter
            memory_importance: Memory importance threshold (1-5)
            max_memory_items: Maximum number of memory items
            tags_filter: Tags filter (comma-separated)
        
        Returns:
            Generated system prompt content
        """
        # Generate team context using team_context_command
        # Use JSON format to get the actual content
        result = self.team_context_command.execute(
            team_name=team_name,
            action="generate",
            mode=mode,
            stages=stages,
            memory_types=memory_types,
            output_format="json",  # Use JSON to get content in result
            save_results=False,  # Don't save since we're just using as prompt
            project_scope=project_scope,
            memory_importance=memory_importance,
            max_memory_items=max_memory_items,
            tags_filter=tags_filter,
            user_message=user_message
        )
        
        if not result.success:
            raise ValueError(f"Failed to generate team context: {result.message}")
        
        # Get the generated context content
        if hasattr(result, 'data') and result.data and 'content' in result.data:
            return result.data['content']
        
        # Fallback: try to generate a basic context
        return f"""You are an AI assistant working with the {team_name} team.

Team Context Generation Mode: {mode}
Project Scope: {project_scope or 'General'}

Please provide helpful, accurate, and context-aware responses based on the team's needs and previous experiences."""

    def chat_with_context(
        self,
        user_message: str,
        team_name: str,
        system_prompt_override: Optional[str] = None,
        mode: str = "hybrid",
        stages: Optional[str] = None,
        memory_types: str = "all",
        project_scope: Optional[str] = None,
        memory_importance: int = 2,
        max_memory_items: int = 50,
        tags_filter: Optional[str] = None,
        max_tokens: int = 20000,
        temperature: float = 1.0
    ) -> Dict[str, Any]:
        """
        Chat with Claude using team context as system prompt
        
        Args:
            user_message: User's message/question
            team_name: Team name for context generation
            system_prompt_override: Optional override for system prompt
            mode: Team context generation mode
            stages: Framework stages for context
            memory_types: Memory types to include
            project_scope: Project scope filter
            memory_importance: Memory importance threshold
            max_memory_items: Maximum memory items
            tags_filter: Tags filter
            max_tokens: Maximum tokens for response
            temperature: Temperature for response generation
        
        Returns:
            Response dictionary with content, usage info, and metadata
        """
        start_time = time.time()
        
        try:
            # Generate system prompt from team context
            if system_prompt_override:
                system_prompt = system_prompt_override
            else:
                system_prompt = self.generate_team_context_system_prompt(
                    team_name=team_name,
                    user_message=user_message,
                    mode=mode,
                    stages=stages,
                    memory_types=memory_types,
                    project_scope=project_scope,
                    memory_importance=memory_importance,
                    max_memory_items=max_memory_items,
                    tags_filter=tags_filter
                )
            
            # Make API call to Claude
            message = self.client.messages.create(
                model=self.model,
                max_tokens=max_tokens,
                temperature=temperature,
                system=system_prompt,
                messages=[
                    {
                        "role": "user",
                        "content": user_message
                    }
                ]
            )
            
            end_time = time.time()
            
            return {
                "success": True,
                "content": message.content[0].text,
                "usage": {
                    "input_tokens": message.usage.input_tokens,
                    "output_tokens": message.usage.output_tokens,
                    "total_tokens": message.usage.input_tokens + message.usage.output_tokens
                },
                "metadata": {
                    "model": self.model,
                    "team_name": team_name,
                    "context_mode": mode,
                    "response_time": end_time - start_time,
                    "timestamp": datetime.now().isoformat(),
                    "system_prompt_length": len(system_prompt),
                    "user_message_length": len(user_message)
                },
                "system_prompt": system_prompt if len(system_prompt) < 2000 else system_prompt[:2000] + "...",
                "error": None
            }
            
        except Exception as e:
            end_time = time.time()
            return {
                "success": False,
                "content": None,
                "usage": None,
                "metadata": {
                    "model": self.model,
                    "team_name": team_name,
                    "context_mode": mode,
                    "response_time": end_time - start_time,
                    "timestamp": datetime.now().isoformat(),
                    "error_type": type(e).__name__
                },
                "system_prompt": None,
                "error": str(e)
            }
    
    def save_conversation(
        self,
        conversation_data: Dict[str, Any],
        output_dir: str = "output/conversations",
        filename: Optional[str] = None
    ) -> Path:
        """
        Save conversation to file
        
        Args:
            conversation_data: Conversation data from chat_with_context
            output_dir: Output directory
            filename: Optional filename (auto-generated if None)
        
        Returns:
            Path to saved file
        """
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)
        
        if filename is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            team_name = conversation_data.get("metadata", {}).get("team_name", "unknown")
            filename = f"{timestamp}_{team_name}_conversation.json"
        
        if not filename.endswith('.json'):
            filename += '.json'
        
        file_path = output_path / filename
        
        with open(file_path, 'w', encoding='utf-8') as f:
            json.dump(conversation_data, f, indent=2, ensure_ascii=False)
        
        return file_path


def create_claude_client(api_key: Optional[str] = None, model: str = "claude-sonnet-4-20250514") -> ClaudeAPIClient:
    """
    Convenience function to create a Claude API client
    
    Args:
        api_key: Anthropic API key (if None, loads from environment)
        model: Claude model to use
    
    Returns:
        ClaudeAPIClient instance
    """
    return ClaudeAPIClient(api_key=api_key, model=model)


def quick_chat(
    user_message: str,
    team_name: str,
    mode: str = "hybrid",
    api_key: Optional[str] = None,
    save_to_file: bool = False
) -> str:
    """
    Quick chat function for simple interactions
    
    Args:
        user_message: User's message
        team_name: Team name for context
        mode: Context generation mode
        api_key: Optional API key
        save_to_file: Whether to save conversation to file
    
    Returns:
        Claude's response content
    """
    client = create_claude_client(api_key=api_key)
    
    result = client.chat_with_context(
        user_message=user_message,
        team_name=team_name,
        mode=mode
    )
    
    if save_to_file and result["success"]:
        client.save_conversation(result)
    
    if result["success"]:
        return result["content"]
    else:
        raise Exception(f"Chat failed: {result['error']}")


# Example usage function
def example_usage():
    """Example usage of the Claude API client"""
    print("ü§ñ Claude API Client Example")
    print("=" * 40)
    
    try:
        # Create client
        client = create_claude_client()
        print("‚úÖ Claude client created successfully")
        
        # Example chat with context
        team_name = "frontend-team"  # Assuming this team exists in test_data
        user_message = "Please help me design a React component for user authentication."
        
        print(f"\nüîÑ Generating context for team: {team_name}")
        print(f"üí¨ User message: {user_message}")
        
        result = client.chat_with_context(
            user_message=user_message,
            team_name=team_name,
            mode="hybrid",
            max_tokens=20000,
            temperature=0.7
        )
        
        if result["success"]:
            print(f"\n‚úÖ Response received:")
            print(f"üìù Content length: {len(result['content'])} characters")
            print(f"üî¢ Token usage: {result['usage']['total_tokens']} tokens")
            print(f"‚è±Ô∏è  Response time: {result['metadata']['response_time']:.2f} seconds")
            print(f"\nüìÑ Response preview:")
            print(result["content"][:500] + "..." if len(result["content"]) > 500 else result["content"])
            
            # Save conversation
            saved_path = client.save_conversation(result)
            print(f"\nüíæ Conversation saved to: {saved_path}")
            
        else:
            print(f"\n‚ùå Chat failed: {result['error']}")
            
    except Exception as e:
        print(f"\n‚ùå Error: {e}")


if __name__ == "__main__":
    example_usage() 