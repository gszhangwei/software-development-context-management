#!/usr/bin/env python3
"""
å¤šæ¨¡å‹AI APIé›†æˆæµ‹è¯•è¿è¡Œå™¨

åŠŸèƒ½ç‰¹æ€§ï¼š
1. ğŸ¤– å¤šæ¨¡å‹æ”¯æŒï¼šåŒæ—¶æ”¯æŒ Claude å’Œ OpenAI æ¨¡å‹
2. ğŸ” æ™ºèƒ½æ£€æµ‹ï¼šè‡ªåŠ¨æ£€æµ‹ .env æ–‡ä»¶ä¸­çš„ API keys
3. ğŸ¥‡ ä¼˜å…ˆçº§é€»è¾‘ï¼šClaude > OpenAIï¼ˆå¦‚æœä¸¤ä¸ªéƒ½å¯ç”¨ï¼Œä¼˜å…ˆä½¿ç”¨ Claudeï¼‰
4. âš™ï¸  è‡ªé€‚åº”é…ç½®ï¼šæ ¹æ®æ¨¡å‹ç±»å‹è‡ªåŠ¨è°ƒæ•´å‚æ•°ï¼ˆå¦‚ max_tokensï¼‰
5. ğŸ§ª ç»¼åˆæµ‹è¯•ï¼šAPIè¿æ¥ã€ä¸Šä¸‹æ–‡ç”Ÿæˆã€é›†æˆæµ‹è¯•
6. ğŸ“Š æ‰¹é‡æµ‹è¯•ï¼šæ”¯æŒæµ‹è¯•æ‰€æœ‰å¯ç”¨æ¨¡å‹
7. ğŸ’¾ ç»“æœä¿å­˜ï¼šè‡ªåŠ¨ä¿å­˜ç³»ç»Ÿæç¤ºè¯ã€AIå“åº”å’Œå…ƒæ•°æ®
8. ğŸ¯ æ¼”ç¤ºæ¨¡å¼ï¼šå¯è§†åŒ–å±•ç¤º API key ä¼˜å…ˆçº§é€»è¾‘

æ”¯æŒçš„æ¨¡å‹ï¼š
- Claude: claude-sonnet-4-20250514, claude-3-5-sonnet-20241022, claude-3-5-haiku-20241022, claude-3-opus-20240229
- OpenAI: gpt-4o, gpt-4o-mini, gpt-4-turbo, gpt-3.5-turbo

ä½¿ç”¨æ–¹æ³•ï¼š
1. åœ¨é¡¹ç›®æ ¹ç›®å½•åˆ›å»º .env æ–‡ä»¶å¹¶é…ç½® API keys
2. è¿è¡Œ python claude_test_runner.py
3. é€‰æ‹©æµ‹è¯•æ¨¡å¼è¿›è¡Œæµ‹è¯•
"""

import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

from src.agent.claude import (
    create_model_runner, 
    list_available_models, 
    get_models_by_provider
)
from src.agent.env_config import get_env_config


def detect_available_models() -> dict:
    """
    æ£€æµ‹å¯ç”¨çš„æ¨¡å‹
    
    Returns:
        åŒ…å«å¯ç”¨æ¨¡å‹ä¿¡æ¯çš„å­—å…¸
    """
    print("ğŸ” æ£€æµ‹å¯ç”¨çš„APIé…ç½®...")
    
    # è·å–ç¯å¢ƒé…ç½®
    env_config = get_env_config()
    
    available_models = {
        "claude": [],
        "openai": [],
        "selected_model": None,
        "selected_provider": None
    }
    
    # æ£€æŸ¥Claude API Key
    if env_config.anthropic_api_key:
        claude_models = get_models_by_provider("anthropic")
        available_models["claude"] = claude_models
        print(f"âœ… å‘ç° Claude API Keyï¼Œå¯ç”¨æ¨¡å‹: {len(claude_models)}ä¸ª")
        for model in claude_models[:3]:  # æ˜¾ç¤ºå‰3ä¸ª
            print(f"   - {model}")
        if len(claude_models) > 3:
            print(f"   - ...è¿˜æœ‰{len(claude_models) - 3}ä¸ªæ¨¡å‹")
    else:
        print("âŒ æœªæ‰¾åˆ° ANTHROPIC_API_KEY")
    
    # æ£€æŸ¥OpenAI API Key
    if env_config.openai_api_key:
        openai_models = get_models_by_provider("openai")
        available_models["openai"] = openai_models
        print(f"âœ… å‘ç° OpenAI API Keyï¼Œå¯ç”¨æ¨¡å‹: {len(openai_models)}ä¸ª")
        for model in openai_models[:3]:  # æ˜¾ç¤ºå‰3ä¸ª
            print(f"   - {model}")
        if len(openai_models) > 3:
            print(f"   - ...è¿˜æœ‰{len(openai_models) - 3}ä¸ªæ¨¡å‹")
    else:
        print("âŒ æœªæ‰¾åˆ° OPENAI_API_KEY")
    
    # é€‰æ‹©æ¨¡å‹ï¼ˆä¼˜å…ˆçº§ï¼šClaude > OpenAIï¼‰
    if available_models["claude"]:
        available_models["selected_model"] = "claude-sonnet-4-20250514"  # é»˜è®¤Claudeæ¨¡å‹
        available_models["selected_provider"] = "claude"
        print(f"ğŸ¯ é€‰æ‹© Claude æ¨¡å‹: {available_models['selected_model']}")
    elif available_models["openai"]:
        available_models["selected_model"] = "o3"  # é»˜è®¤OpenAIæ¨¡å‹
        available_models["selected_provider"] = "openai"
        print(f"ğŸ¯ é€‰æ‹© OpenAI æ¨¡å‹: {available_models['selected_model']}")
    else:
        print("âŒ æœªæ‰¾åˆ°ä»»ä½•å¯ç”¨çš„APIå¯†é’¥!")
        print("ğŸ’¡ è¯·åœ¨é¡¹ç›®æ ¹ç›®å½•åˆ›å»º .env æ–‡ä»¶å¹¶é…ç½®ä»¥ä¸‹ä»»ä¸€å¯†é’¥:")
        print("   ANTHROPIC_API_KEY=your_claude_api_key")
        print("   OPENAI_API_KEY=your_openai_api_key")
    
    return available_models


def load_user_message(file_path: str = "user_message.txt") -> str:
    """
    ä»æ–‡ä»¶åŠ è½½ç”¨æˆ·æ¶ˆæ¯
    
    Args:
        file_path: æ¶ˆæ¯æ–‡ä»¶è·¯å¾„
        
    Returns:
        ç”¨æˆ·æ¶ˆæ¯å†…å®¹ï¼Œå¦‚æœæ–‡ä»¶ä¸å­˜åœ¨åˆ™è¿”å›None
    """
    try:
        file_path = Path(file_path)
        if file_path.exists():
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read().strip()
                if content:
                    print(f"âœ… ä» '{file_path}' åŠ è½½ç”¨æˆ·æ¶ˆæ¯æˆåŠŸ")
                    print(f"ğŸ“„ æ¶ˆæ¯é¢„è§ˆ: {content[:100]}{'...' if len(content) > 100 else ''}")
                    return content
                else:
                    print(f"âš ï¸  æ–‡ä»¶ '{file_path}' ä¸ºç©º")
                    return None
        else:
            print(f"ğŸ“ æœªæ‰¾åˆ°æ¶ˆæ¯æ–‡ä»¶ '{file_path}'ï¼Œå°†ä½¿ç”¨é»˜è®¤æµ‹è¯•æ¶ˆæ¯")
            return None
    except Exception as e:
        print(f"âŒ è¯»å–æ¶ˆæ¯æ–‡ä»¶å¤±è´¥: {e}")
        return None


def main(message_file: str = "user_message.txt", model_name: str = None, context_mode: str = "hybrid"):
    """
    ä¸»å‡½æ•°
    
    Args:
        message_file: ç”¨æˆ·æ¶ˆæ¯æ–‡ä»¶è·¯å¾„
        model_name: å¯é€‰çš„æŒ‡å®šæ¨¡å‹åç§°ï¼Œå¦‚æœä¸æä¾›åˆ™è‡ªåŠ¨æ£€æµ‹
        context_mode: ä¸Šä¸‹æ–‡æ¨¡å¼ (framework_only, memory_only, hybrid)
    """
    print("ğŸš€ å¯åŠ¨å¤šæ¨¡å‹AI APIé›†æˆæµ‹è¯•")
    print("=" * 60)
    
    try:
        # æ£€æµ‹å¯ç”¨æ¨¡å‹
        available_models = detect_available_models()
        
        # å¦‚æœæ²¡æœ‰æŒ‡å®šæ¨¡å‹ï¼Œä½¿ç”¨è‡ªåŠ¨æ£€æµ‹çš„æ¨¡å‹
        if model_name is None:
            model_name = available_models["selected_model"]
        
        if not model_name:
            return {"success": False, "error": "æ²¡æœ‰å¯ç”¨çš„APIå¯†é’¥æˆ–æ¨¡å‹"}
        
        # åŠ è½½ç”¨æˆ·æ¶ˆæ¯
        user_message = load_user_message(message_file)
        
        print(f"\n" + "=" * 60)
        print(f"ğŸ¤– å¼€å§‹æµ‹è¯•æ¨¡å‹: {model_name}")
        print(f"ğŸ”§ ä¸Šä¸‹æ–‡æ¨¡å¼: {context_mode}")
        print("=" * 60)
        
        # åˆ›å»ºæ¨¡å‹è¿è¡Œå™¨
        runner = create_model_runner(
            model_name=model_name,
            team_data_root="test_data",
            output_dir="output"
        )
        
        print("âœ… æ¨¡å‹è¿è¡Œå™¨åˆ›å»ºæˆåŠŸ")
        
        # æ˜¾ç¤ºè¿è¡Œå™¨ä¿¡æ¯
        info = runner.get_runner_info()
        print(f"ğŸ“‹ è¿è¡Œå™¨é…ç½®:")
        print(f"   - æ¨¡å‹: {info['model_name']}")
        print(f"   - æä¾›å•†: {available_models['selected_provider']}")
        print(f"   - å›¢é˜Ÿæ•°æ®: {info['team_data_root']}")
        print(f"   - è¾“å‡ºç›®å½•: {info['output_dir']}")
        print(f"   - å¯ç”¨å›¢é˜Ÿ: {len(info['usage_info']['available_teams'])}ä¸ª")
        
        # è¿è¡Œç»¼åˆæµ‹è¯•
        print(f"\nğŸ”„ å¼€å§‹è¿è¡Œç»¼åˆæµ‹è¯•...")
        result = runner.run_comprehensive_test(user_message, context_mode)
        
        # æ·»åŠ æ¨¡å‹ä¿¡æ¯åˆ°ç»“æœ
        result["model_info"] = {
            "selected_model": model_name,
            "selected_provider": available_models["selected_provider"],
            "available_models": available_models,
            "context_mode": context_mode
        }
        
        return result
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿è¡Œå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return {"success": False, "error": str(e)}


def test_all_available_models(context_mode: str = "hybrid"):
    """æµ‹è¯•æ‰€æœ‰å¯ç”¨çš„æ¨¡å‹
    
    Args:
        context_mode: ä¸Šä¸‹æ–‡æ¨¡å¼ (framework_only, memory_only, hybrid)
    """
    print("ğŸ§ª æµ‹è¯•æ‰€æœ‰å¯ç”¨æ¨¡å‹")
    print(f"ğŸ”§ ä½¿ç”¨ä¸Šä¸‹æ–‡æ¨¡å¼: {context_mode}")
    print("=" * 60)
    
    # æ£€æµ‹å¯ç”¨æ¨¡å‹
    available_models = detect_available_models()
    
    all_models = available_models["claude"] + available_models["openai"]
    
    if not all_models:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°å¯ç”¨çš„æ¨¡å‹")
        return
    
    results = {}
    
    for model_name in all_models:
        print(f"\n" + "=" * 40)
        print(f"ğŸ”„ æµ‹è¯•æ¨¡å‹: {model_name}")
        print("=" * 40)
        
        try:
            result = main("user_message.txt", model_name, context_mode)
            results[model_name] = result
            
            if result.get("success", False):
                print(f"âœ… {model_name} æµ‹è¯•æˆåŠŸ")
            else:
                print(f"âŒ {model_name} æµ‹è¯•å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
                
        except Exception as e:
            print(f"âŒ {model_name} æµ‹è¯•å¼‚å¸¸: {e}")
            results[model_name] = {"success": False, "error": str(e)}
    
    # æ˜¾ç¤ºæ±‡æ€»ç»“æœ
    print(f"\n" + "=" * 60)
    print("ğŸ“Š æ‰€æœ‰æ¨¡å‹æµ‹è¯•ç»“æœæ±‡æ€»")
    print("=" * 60)
    
    for model_name, result in results.items():
        status = "âœ… æˆåŠŸ" if result.get("success", False) else "âŒ å¤±è´¥"
        print(f"{model_name}: {status}")
    
    return results


def quick_test():
    """å¿«é€Ÿæµ‹è¯•å‡½æ•°"""
    try:
        from src.agent.claude import create_ai_model, create_model_usage_manager, create_model_storage_manager
        
        print("ğŸ§ª å¿«é€ŸåŠŸèƒ½æµ‹è¯•")
        print("=" * 30)
        
        # æ£€æµ‹å¯ç”¨æ¨¡å‹
        available_models = detect_available_models()
        
        if not available_models["selected_model"]:
            print("âŒ æ²¡æœ‰å¯ç”¨çš„æ¨¡å‹è¿›è¡Œæµ‹è¯•")
            return False
        
        model_name = available_models["selected_model"]
        
        # æµ‹è¯•æ¨¡å‹åˆ›å»º
        model = create_ai_model(model_name)
        print(f"âœ… æ¨¡å‹åˆ›å»ºæˆåŠŸ: {model_name}")
        
        # æµ‹è¯•ä½¿ç”¨ç®¡ç†å™¨
        usage = create_model_usage_manager(model_name)
        teams = usage.get_available_teams()
        print(f"âœ… ä½¿ç”¨ç®¡ç†å™¨åˆ›å»ºæˆåŠŸï¼Œå‘ç°{len(teams)}ä¸ªå›¢é˜Ÿ")
        
        # æµ‹è¯•å­˜å‚¨ç®¡ç†å™¨
        storage = create_model_storage_manager()
        storage_info = storage.get_storage_info()
        print(f"âœ… å­˜å‚¨ç®¡ç†å™¨åˆ›å»ºæˆåŠŸ")
        
        print("\nğŸ“ å­˜å‚¨ç›®å½•ç»“æ„:")
        print(f"   - ç³»ç»Ÿæç¤ºè¯: {storage_info['system_prompts_dir']}")
        print(f"   - AIå“åº”: {storage_info['responses_dir']}")
        print(f"   - å…ƒæ•°æ®: {storage_info['metadata_dir']}")
        
        return True
        
    except Exception as e:
        print(f"âŒ å¿«é€Ÿæµ‹è¯•å¤±è´¥: {e}")
        return False


def demo_usage():
    """ä½¿ç”¨æ¼”ç¤º"""
    print("\nğŸ’¡ ä½¿ç”¨æ¼”ç¤º")
    print("=" * 30)
    
    print("# åŸºæœ¬ä½¿ç”¨æ–¹æ³•:")
    print("""
# 1. é…ç½® API Keysï¼ˆåœ¨é¡¹ç›®æ ¹ç›®å½•åˆ›å»º .env æ–‡ä»¶ï¼‰
# å¯¹äº Claude (ç¬¬ä¸€ä¼˜å…ˆçº§):
ANTHROPIC_API_KEY=your_claude_api_key_here

# å¯¹äº OpenAI (ç¬¬äºŒä¼˜å…ˆçº§):
OPENAI_API_KEY=your_openai_api_key_here

# é‡è¦ï¼š
# - å¦‚æœä¸¤ä¸ªéƒ½é…ç½®ï¼Œä¼šä¼˜å…ˆä½¿ç”¨ Claude
# - åªéœ€è¦é…ç½®ä¸€ä¸ªå³å¯æ­£å¸¸å·¥ä½œ
# - ç³»ç»Ÿä¼šè‡ªåŠ¨æ£€æµ‹å¹¶é€‰æ‹©æœ€ä½³æ¨¡å‹

# 2. åˆ›å»ºç”¨æˆ·æ¶ˆæ¯æ–‡ä»¶ (user_message.txt)
echo "è¯·å¸®æˆ‘è®¾è®¡ä¸€ä¸ªç”¨æˆ·è®¤è¯API" > user_message.txt

# 3. è¿è¡Œæµ‹è¯•ï¼ˆä¼šè‡ªåŠ¨æ£€æµ‹å¹¶é€‰æ‹©åˆé€‚çš„æ¨¡å‹å’Œæ··åˆæ¨¡å¼ï¼‰
python claude_test_runner.py

# 4. æˆ–è€…æŒ‡å®šè‡ªå®šä¹‰æ¶ˆæ¯æ–‡ä»¶å’Œä¸Šä¸‹æ–‡æ¨¡å¼
from claude_test_runner import main
main("my_custom_message.txt", None, "hybrid")  # ä½¿ç”¨æ··åˆæ¨¡å¼
main("my_custom_message.txt", None, "framework_only")  # ä»…ä½¿ç”¨æ¡†æ¶
main("my_custom_message.txt", None, "memory_only")  # ä»…ä½¿ç”¨è®°å¿†

# 5. æŒ‡å®šç‰¹å®šæ¨¡å‹å’Œä¸Šä¸‹æ–‡æ¨¡å¼
main("user_message.txt", "gpt-4o", "hybrid")  # OpenAI + æ··åˆæ¨¡å¼
main("user_message.txt", "claude-sonnet-4-20250514", "hybrid")  # Claude + æ··åˆæ¨¡å¼

# 6. æµ‹è¯•æ‰€æœ‰å¯ç”¨æ¨¡å‹ï¼ˆä½¿ç”¨æ··åˆæ¨¡å¼ï¼‰
from claude_test_runner import test_all_available_models
test_all_available_models("hybrid")
test_all_available_models("framework_only")
""")

    print("# ä¸Šä¸‹æ–‡æ¨¡å¼è¯¦è§£:")
    print("""
æ··åˆæ¨¡å¼ (hybrid) - æ¨èæ¨¡å¼:
- ç»“åˆå›¢é˜Ÿè®°å¿†å’Œä¸ƒé˜¶æ®µæ¡†æ¶
- ä¸ºæ¯ä¸ªæ¡†æ¶é˜¶æ®µæ·»åŠ ç›¸å…³çš„å†å²ç»éªŒ
- æä¾›æœ€å…¨é¢çš„ä¸Šä¸‹æ–‡ä¿¡æ¯
- é€‚ç”¨äºå¤æ‚é¡¹ç›®å’Œéœ€è¦ç»¼åˆè€ƒè™‘çš„åœºæ™¯

ä»…æ¡†æ¶æ¨¡å¼ (framework_only):
- åªä½¿ç”¨ä¸ƒé˜¶æ®µæ¡†æ¶æ¨¡æ¿
- æ ‡å‡†åŒ–çš„ç»“æ„å’Œæµç¨‹
- é€‚ç”¨äºæ–°é¡¹ç›®å¯åŠ¨å’Œæ ‡å‡†åŒ–å¼€å‘

ä»…è®°å¿†æ¨¡å¼ (memory_only):
- åªä½¿ç”¨å›¢é˜Ÿå†å²è®°å¿†
- åŸºäºè¿‡å¾€ç»éªŒçš„å»ºè®®
- é€‚ç”¨äºå›é¡¾å’Œç»éªŒæ€»ç»“
""")

    print("# æ”¯æŒçš„æ¨¡å‹:")
    print("""
Claude æ¨¡å‹:
- claude-sonnet-4-20250514
- claude-3-5-sonnet-20241022
- claude-3-5-haiku-20241022
- claude-3-opus-20240229

OpenAI æ¨¡å‹:
- gpt-4o
- gpt-4o-mini
- gpt-4-turbo
- gpt-3.5-turbo
""")

    print("# åˆ†å¼€çš„æ¨¡å—ä½¿ç”¨:")
    print("""
# æ£€æµ‹å¯ç”¨æ¨¡å‹
from claude_test_runner import detect_available_models
models = detect_available_models()

# ä½¿ç”¨ç‰¹å®šæ¨¡å‹å’Œæ··åˆæ¨¡å¼
from src.agent.claude import create_ai_model
model = create_ai_model("gpt-4o")  # OpenAI
model = create_ai_model("claude-sonnet-4-20250514")  # Claude

# åˆ›å»ºè¿è¡Œå™¨å¹¶ä½¿ç”¨æ··åˆæ¨¡å¼
from src.agent.claude import create_model_runner
runner = create_model_runner("gpt-4o")
result = runner.run_with_context(
    user_message="è®¾è®¡ä¸€ä¸ªAPI",
    team_name="engineering_team", 
    mode="hybrid"  # ä½¿ç”¨æ··åˆæ¨¡å¼
)
""")


def create_sample_message_file():
    """åˆ›å»ºç¤ºä¾‹æ¶ˆæ¯æ–‡ä»¶"""
    sample_content = """## èƒŒæ™¯
æˆ‘éœ€è¦ä¸ºä¸€ä¸ªç”µå•†å¹³å°è®¾è®¡ç”¨æˆ·è®¤è¯å’Œæˆæƒç³»ç»Ÿã€‚

## éœ€æ±‚
1. ç”¨æˆ·æ³¨å†Œå’Œç™»å½•åŠŸèƒ½
2. JWT tokenç®¡ç†
3. è§’è‰²æƒé™æ§åˆ¶ï¼ˆæ™®é€šç”¨æˆ·ã€ç®¡ç†å‘˜ï¼‰
4. å¯†ç é‡ç½®åŠŸèƒ½
5. å¤šç«¯ç™»å½•æ”¯æŒ

## æŠ€æœ¯æ ˆ
- åç«¯ï¼šPython FastAPI
- æ•°æ®åº“ï¼šPostgreSQL
- ç¼“å­˜ï¼šRedis

è¯·å¸®æˆ‘è®¾è®¡è¿™ä¸ªè®¤è¯ç³»ç»Ÿçš„å®Œæ•´æ–¹æ¡ˆã€‚"""
    
    try:
        with open("user_message.txt", "w", encoding="utf-8") as f:
            f.write(sample_content)
        print("âœ… å·²åˆ›å»ºç¤ºä¾‹æ¶ˆæ¯æ–‡ä»¶ 'user_message.txt'")
        return True
    except Exception as e:
        print(f"âŒ åˆ›å»ºç¤ºä¾‹æ–‡ä»¶å¤±è´¥: {e}")
        return False


def create_sample_env_file():
    """åˆ›å»ºç¤ºä¾‹ .env æ–‡ä»¶"""
    sample_content = """# AI API Keys Configuration
# é…ç½®ä½ çš„ AI API å¯†é’¥ï¼ˆåªéœ€è¦é…ç½®å…¶ä¸­ä¸€ä¸ªï¼Œæˆ–ä¸¤ä¸ªéƒ½é…ç½®ï¼‰

# Claude (Anthropic) API Key - ä¼˜å…ˆçº§æ›´é«˜
# è·å–åœ°å€: https://console.anthropic.com/
ANTHROPIC_API_KEY=your_claude_api_key_here

# OpenAI API Key - å¦‚æœæ²¡æœ‰ Claude key ä¼šä½¿ç”¨è¿™ä¸ª
# è·å–åœ°å€: https://platform.openai.com/api-keys
OPENAI_API_KEY=your_openai_api_key_here

# æ³¨æ„:
# 1. è¯·å°† "your_xxx_api_key_here" æ›¿æ¢ä¸ºä½ çš„çœŸå® API key
# 2. å¦‚æœä¸¤ä¸ª key éƒ½é…ç½®ï¼Œä¼šä¼˜å…ˆä½¿ç”¨ Claude
# 3. è‡³å°‘éœ€è¦é…ç½®ä¸€ä¸ª key æ‰èƒ½æ­£å¸¸å·¥ä½œ
"""
    
    try:
        with open(".env", "w", encoding="utf-8") as f:
            f.write(sample_content)
        print("âœ… å·²åˆ›å»ºç¤ºä¾‹ .env æ–‡ä»¶")
        print("âš ï¸  è¯·ç¼–è¾‘ .env æ–‡ä»¶ï¼Œæ·»åŠ ä½ çš„çœŸå® API keys")
        return True
    except Exception as e:
        print(f"âŒ åˆ›å»ºç¤ºä¾‹ .env æ–‡ä»¶å¤±è´¥: {e}")
        return False


def demo_priority_logic():
    """æ¼”ç¤ºAPI keyä¼˜å…ˆçº§é€»è¾‘"""
    print("ğŸ¯ API Key ä¼˜å…ˆçº§æ¼”ç¤º")
    print("=" * 50)
    
    # æ¨¡æ‹Ÿä¸åŒçš„ç¯å¢ƒé…ç½®åœºæ™¯
    scenarios = [
        {
            "name": "åªæœ‰ Claude API Key",
            "anthropic_api_key": "sk-ant-xxx",
            "openai_api_key": None
        },
        {
            "name": "åªæœ‰ OpenAI API Key", 
            "anthropic_api_key": None,
            "openai_api_key": "sk-xxx"
        },
        {
            "name": "ä¸¤ä¸ª API Key éƒ½å­˜åœ¨",
            "anthropic_api_key": "sk-ant-xxx",
            "openai_api_key": "sk-xxx"
        },
        {
            "name": "æ²¡æœ‰ä»»ä½• API Key",
            "anthropic_api_key": None,
            "openai_api_key": None
        }
    ]
    
    for i, scenario in enumerate(scenarios, 1):
        print(f"\nğŸ“‹ åœºæ™¯ {i}: {scenario['name']}")
        print("-" * 30)
        
        # æ¨¡æ‹Ÿæ£€æµ‹é€»è¾‘
        claude_available = bool(scenario["anthropic_api_key"])
        openai_available = bool(scenario["openai_api_key"])
        
        print(f"Claude API Key: {'âœ… å¯ç”¨' if claude_available else 'âŒ æœªé…ç½®'}")
        print(f"OpenAI API Key: {'âœ… å¯ç”¨' if openai_available else 'âŒ æœªé…ç½®'}")
        
        # åº”ç”¨ä¼˜å…ˆçº§é€»è¾‘
        if claude_available:
            selected = "Claude (claude-sonnet-4-20250514)"
            priority = "ğŸ¥‡ ç¬¬ä¸€ä¼˜å…ˆçº§"
        elif openai_available:
            selected = "OpenAI (gpt-4o)"
            priority = "ğŸ¥ˆ ç¬¬äºŒä¼˜å…ˆçº§"
        else:
            selected = "æ— å¯ç”¨æ¨¡å‹"
            priority = "âŒ éœ€è¦é…ç½®API key"
        
        print(f"é€‰æ‹©ç»“æœ: {selected}")
        print(f"é€‰æ‹©åŸå› : {priority}")


def run_non_interactive():
    """éäº¤äº’å¼è¿è¡Œæ¨¡å¼"""
    print("ğŸ¤– éäº¤äº’å¼æµ‹è¯•æ¨¡å¼")
    print("=" * 50)
    
    # ç›´æ¥è¿è¡Œå®Œæ•´æµ‹è¯•
    result = main("user_message.txt")
    
    if result and result.get("overall_success"):
        print("\nğŸ‰ éäº¤äº’å¼æµ‹è¯•å®Œæˆä¸”æˆåŠŸï¼")
    elif result and result.get("success_count", 0) > 0:
        print(f"\nâœ… éäº¤äº’å¼æµ‹è¯•éƒ¨åˆ†æˆåŠŸï¼é€šè¿‡ {result.get('success_count', 0)}/{result.get('total_tests', 3)} ä¸ªæµ‹è¯•")
    else:
        print(f"\nâŒ éäº¤äº’å¼æµ‹è¯•å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯') if result else 'æ— ç»“æœ'}")
    
    return result


if __name__ == "__main__":
    import os
    
    # æ£€æŸ¥æ˜¯å¦æœ‰éäº¤äº’å¼ç¯å¢ƒå˜é‡
    if os.getenv("NON_INTERACTIVE") or "--non-interactive" in sys.argv:
        run_non_interactive()
    else:
        # åŸæœ‰çš„äº¤äº’å¼é€»è¾‘
        # è¿è¡Œå¿«é€Ÿæµ‹è¯•
        if quick_test():
            print("\n" + "=" * 60)
            
            # æ£€æŸ¥æ˜¯å¦å­˜åœ¨æ¶ˆæ¯æ–‡ä»¶
            message_file = Path("user_message.txt")
            if not message_file.exists():
                print(f"ğŸ“ æœªæ‰¾åˆ°æ¶ˆæ¯æ–‡ä»¶ '{message_file}'")
                try:
                    create_file = input("æ˜¯å¦åˆ›å»ºç¤ºä¾‹æ¶ˆæ¯æ–‡ä»¶ï¼Ÿ(y/n): ").lower()
                    if create_file.startswith('y'):
                        create_sample_message_file()
                except KeyboardInterrupt:
                    print("\n\nğŸ‘‹ å·²å–æ¶ˆ")
            
            # æ£€æŸ¥æ˜¯å¦å­˜åœ¨ .env æ–‡ä»¶
            env_file = Path(".env")
            if not env_file.exists():
                print(f"ğŸ“ æœªæ‰¾åˆ° .env é…ç½®æ–‡ä»¶")
                try:
                    create_env = input("æ˜¯å¦åˆ›å»ºç¤ºä¾‹ .env æ–‡ä»¶ï¼Ÿ(y/n): ").lower()
                    if create_env.startswith('y'):
                        create_sample_env_file()
                except KeyboardInterrupt:
                    print("\n\nğŸ‘‹ å·²å–æ¶ˆ")
            
            # è¯¢é—®æ˜¯å¦è¿è¡Œå®Œæ•´æµ‹è¯•
            try:
                response = input("\né€‰æ‹©æµ‹è¯•æ¨¡å¼:\n1. è‡ªåŠ¨æ£€æµ‹å¹¶æµ‹è¯•å•ä¸ªæ¨¡å‹ (y)\n2. æµ‹è¯•æ‰€æœ‰å¯ç”¨æ¨¡å‹ (a)\n3. æ¼”ç¤ºAPI keyä¼˜å…ˆçº§é€»è¾‘ (p)\n4. è·³è¿‡æµ‹è¯• (n)\nè¯·é€‰æ‹© (y/a/p/n): ").lower()
                
                # è¯¢é—®ä¸Šä¸‹æ–‡æ¨¡å¼
                context_mode = "hybrid"  # é»˜è®¤å€¼
                if response.startswith('y') or response.startswith('a'):
                    context_input = input("\né€‰æ‹©ä¸Šä¸‹æ–‡æ¨¡å¼:\n1. æ··åˆæ¨¡å¼ - è®°å¿†+æ¡†æ¶ (hybrid, æ¨è)\n2. ä»…æ¡†æ¶æ¨¡å¼ (framework)\n3. ä»…è®°å¿†æ¨¡å¼ (memory)\nè¯·é€‰æ‹© (hybrid/framework/memory, é»˜è®¤ hybrid): ").lower().strip()
                    
                    if context_input in ['framework', 'framework_only', 'f']:
                        context_mode = "framework_only"
                    elif context_input in ['memory', 'memory_only', 'm']:
                        context_mode = "memory_only"
                    else:
                        context_mode = "hybrid"  # é»˜è®¤ä½¿ç”¨æ··åˆæ¨¡å¼
                    
                    print(f"âœ… å·²é€‰æ‹©ä¸Šä¸‹æ–‡æ¨¡å¼: {context_mode}")
                
                if response.startswith('a'):
                    test_all_available_models(context_mode)
                elif response.startswith('p'):
                    demo_priority_logic()
                elif response.startswith('y'):
                    # è¯¢é—®æ¶ˆæ¯æ–‡ä»¶è·¯å¾„
                    try:
                        file_input = input("æ¶ˆæ¯æ–‡ä»¶è·¯å¾„ (å›è½¦ä½¿ç”¨ 'user_message.txt'): ").strip()
                        message_file_path = file_input if file_input else "user_message.txt"
                        main(message_file_path, None, context_mode)
                    except KeyboardInterrupt:
                        print("\n\nğŸ‘‹ æµ‹è¯•å·²å–æ¶ˆ")
                else:
                    print("âœ… å¿«é€Ÿæµ‹è¯•å®Œæˆ")
                    demo_usage()
            except KeyboardInterrupt:
                print("\n\nğŸ‘‹ æµ‹è¯•å·²å–æ¶ˆ")
        else:
            print("âŒ å¿«é€Ÿæµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®")
            print("\nğŸ’¡ å¯èƒ½çš„è§£å†³æ–¹æ¡ˆ:")
            print("1. ç¡®ä¿å·²å®‰è£…æ‰€æœ‰ä¾èµ–: pip install -r requirements.txt")
            print("2. é…ç½® API keys åœ¨ .env æ–‡ä»¶ä¸­")
            print("3. æ£€æŸ¥ç½‘ç»œè¿æ¥") 