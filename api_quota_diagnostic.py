#!/usr/bin/env python3
"""
OpenAI API é…é¢è¯Šæ–­å·¥å…·

å¸®åŠ©è¯Šæ–­429é”™è¯¯çš„å…·ä½“åŸå› å’Œè§£å†³æ–¹æ¡ˆ
"""

import time
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

from src.agent.env_config import get_env_config

try:
    import openai
    HAS_OPENAI = True
except ImportError:
    HAS_OPENAI = False
    print("âŒ éœ€è¦å®‰è£… openai åº“: pip install openai")
    sys.exit(1)


def test_minimal_api_call():
    """æµ‹è¯•æœ€å°çš„APIè°ƒç”¨"""
    print("ğŸ§ª æµ‹è¯•æœ€å°APIè°ƒç”¨...")
    
    env_config = get_env_config()
    if not env_config.openai_api_key:
        print("âŒ æœªæ‰¾åˆ° OPENAI_API_KEY")
        return False
    
    client = openai.OpenAI(api_key=env_config.openai_api_key)
    
    try:
        # ä½¿ç”¨æœ€å°å‚æ•°
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",  # ä½¿ç”¨æœ€ä¾¿å®œçš„æ¨¡å‹
            max_tokens=10,  # æœ€å°tokenæ•°
            temperature=0,
            messages=[
                {"role": "user", "content": "Hi"}
            ]
        )
        
        print(f"âœ… æœ€å°APIè°ƒç”¨æˆåŠŸ!")
        print(f"ğŸ“Š ä½¿ç”¨tokens: {response.usage.total_tokens}")
        print(f"ğŸ“ å“åº”: {response.choices[0].message.content}")
        return True
        
    except Exception as e:
        print(f"âŒ æœ€å°APIè°ƒç”¨å¤±è´¥: {e}")
        return False


def test_model_availability():
    """æµ‹è¯•ä¸åŒæ¨¡å‹çš„å¯ç”¨æ€§"""
    print("\nğŸ§ª æµ‹è¯•ä¸åŒæ¨¡å‹å¯ç”¨æ€§...")
    
    env_config = get_env_config()
    client = openai.OpenAI(api_key=env_config.openai_api_key)
    
    models_to_test = [
        "gpt-3.5-turbo",
        "gpt-4o-mini", 
        "gpt-4o",
        "gpt-4-turbo"
    ]
    
    results = {}
    
    for model in models_to_test:
        print(f"  ğŸ”„ æµ‹è¯• {model}...")
        try:
            response = client.chat.completions.create(
                model=model,
                max_tokens=5,
                temperature=0,
                messages=[{"role": "user", "content": "Hi"}]
            )
            results[model] = {
                "status": "âœ… æˆåŠŸ",
                "tokens": response.usage.total_tokens
            }
            print(f"    âœ… {model}: {response.usage.total_tokens} tokens")
            
            # æ·»åŠ å»¶è¿Ÿé¿å…é¢‘ç‡é™åˆ¶
            time.sleep(1)
            
        except Exception as e:
            results[model] = {
                "status": "âŒ å¤±è´¥", 
                "error": str(e)
            }
            print(f"    âŒ {model}: {e}")
            
            # å¦‚æœæ˜¯429é”™è¯¯ï¼Œåœæ­¢æµ‹è¯•å…¶ä»–æ¨¡å‹
            if "429" in str(e):
                print("    âš ï¸  æ£€æµ‹åˆ°429é”™è¯¯ï¼Œåœæ­¢æµ‹è¯•å…¶ä»–æ¨¡å‹")
                break
    
    return results


def test_with_delays():
    """æµ‹è¯•å¸¦å»¶è¿Ÿçš„å¤šæ¬¡è°ƒç”¨"""
    print("\nğŸ§ª æµ‹è¯•å¸¦å»¶è¿Ÿçš„å¤šæ¬¡è°ƒç”¨...")
    
    env_config = get_env_config()
    client = openai.OpenAI(api_key=env_config.openai_api_key)
    
    success_count = 0
    total_attempts = 3
    
    for i in range(total_attempts):
        print(f"  ğŸ”„ ç¬¬ {i+1} æ¬¡è°ƒç”¨...")
        try:
            response = client.chat.completions.create(
                model="gpt-3.5-turbo",
                max_tokens=5,
                temperature=0,
                messages=[{"role": "user", "content": f"Test {i+1}"}]
            )
            success_count += 1
            print(f"    âœ… æˆåŠŸ: {response.usage.total_tokens} tokens")
            
        except Exception as e:
            print(f"    âŒ å¤±è´¥: {e}")
            if "429" in str(e):
                print("    â° ç­‰å¾…60ç§’åé‡è¯•...")
                time.sleep(60)
        
        # æ¯æ¬¡è°ƒç”¨é—´éš”
        if i < total_attempts - 1:
            print("    â° ç­‰å¾…5ç§’...")
            time.sleep(5)
    
    print(f"\nğŸ“Š æˆåŠŸç‡: {success_count}/{total_attempts}")
    return success_count > 0


def get_api_key_info():
    """è·å–APIå¯†é’¥ä¿¡æ¯"""
    print("ğŸ”‘ APIå¯†é’¥ä¿¡æ¯:")
    
    env_config = get_env_config()
    if env_config.openai_api_key:
        key = env_config.openai_api_key
        print(f"  - å¯†é’¥é•¿åº¦: {len(key)}")
        print(f"  - å‰ç¼€: {key[:7]}...")
        print(f"  - åç¼€: ...{key[-4:]}")
        
        # æ£€æŸ¥å¯†é’¥æ ¼å¼
        if key.startswith("sk-"):
            print("  - æ ¼å¼: âœ… æ ‡å‡†æ ¼å¼")
        else:
            print("  - æ ¼å¼: âš ï¸  éæ ‡å‡†æ ¼å¼")
    else:
        print("  - âŒ æœªæ‰¾åˆ°APIå¯†é’¥")


def diagnose_429_error():
    """ç»¼åˆè¯Šæ–­429é”™è¯¯"""
    print("ğŸ” OpenAI API é…é¢è¯Šæ–­")
    print("=" * 50)
    
    # 1. æ£€æŸ¥APIå¯†é’¥
    get_api_key_info()
    
    # 2. æµ‹è¯•æœ€å°è°ƒç”¨
    if not test_minimal_api_call():
        print("\nğŸ’¡ å»ºè®®:")
        print("1. æ£€æŸ¥APIå¯†é’¥æ˜¯å¦æ­£ç¡®")
        print("2. æ£€æŸ¥ç½‘ç»œè¿æ¥")
        print("3. ç­‰å¾…ä¸€æ®µæ—¶é—´åé‡è¯•")
        return
    
    # 3. æµ‹è¯•ä¸åŒæ¨¡å‹
    model_results = test_model_availability()
    
    # 4. æµ‹è¯•å»¶è¿Ÿè°ƒç”¨
    delay_success = test_with_delays()
    
    # 5. ç”Ÿæˆå»ºè®®
    print("\nğŸ’¡ è¯Šæ–­ç»“æœå’Œå»ºè®®:")
    print("=" * 30)
    
    success_models = [m for m, r in model_results.items() if "æˆåŠŸ" in r["status"]]
    failed_models = [m for m, r in model_results.items() if "å¤±è´¥" in r["status"]]
    
    if success_models:
        print(f"âœ… å¯ç”¨æ¨¡å‹: {', '.join(success_models)}")
    
    if failed_models:
        print(f"âŒ ä¸å¯ç”¨æ¨¡å‹: {', '.join(failed_models)}")
    
    if delay_success:
        print("âœ… å»¶è¿Ÿè°ƒç”¨æœ‰æ•ˆï¼Œå»ºè®®æ·»åŠ é‡è¯•æœºåˆ¶")
    else:
        print("âŒ å»¶è¿Ÿè°ƒç”¨ä»å¤±è´¥ï¼Œå¯èƒ½éœ€è¦ç­‰å¾…æ›´é•¿æ—¶é—´")
    
    # å…·ä½“å»ºè®®
    print("\nğŸ› ï¸  è§£å†³æ–¹æ¡ˆ:")
    if success_models:
        print(f"1. ä½¿ç”¨å¯ç”¨æ¨¡å‹: {success_models[0]}")
        print("2. å‡å°‘max_tokenså‚æ•°")
        print("3. æ·»åŠ è¯·æ±‚é—´éš”å’Œé‡è¯•æœºåˆ¶")
    
    print("4. æ£€æŸ¥OpenAIè´¦æˆ·è®¡è´¹çŠ¶æ€")
    print("5. ç­‰å¾…é…é¢é‡ç½®ï¼ˆé€šå¸¸1åˆ†é’Ÿæˆ–1å°æ—¶ï¼‰")


if __name__ == "__main__":
    diagnose_429_error() 