# 实现细节文档

## 🔧 核心模块实现

### 1. 上下文处理器 (ContextProcessor)

#### 核心数据结构

```python
@dataclass
class ContextGenerationConfig:
    """上下文生成配置"""
    team_name: str
    project_name: Optional[str] = None
    mode: ContextMode = ContextMode.HYBRID
    
    # 记忆相关配置
    include_memory_types: List[MemoryType] = field(default_factory=lambda: [MemoryType.ALL])
    max_memory_items: int = 50
    memory_importance_threshold: int = 2
    include_team_memories: bool = True
    
    # 框架相关配置
    include_framework_stages: List[str] = field(default_factory=lambda: [
        "requirements", "business-model", "solution", "structure", 
        "tasks", "common-tasks", "constraints"
    ])
    
    # 过滤条件
    project_scope: Optional[str] = None
    time_range: Optional[Tuple[str, str]] = None
    memory_filters: Dict[str, Any] = field(default_factory=dict)

@dataclass  
class GeneratedContext:
    """生成的上下文结果"""
    team_name: str
    mode: ContextMode
    content: str
    source_memories: List[str] = field(default_factory=list)
    framework_stages: List[str] = field(default_factory=list)
    metadata: Dict[str, Any] = field(default_factory=dict)
    generation_time: str = field(default_factory=lambda: datetime.now().isoformat())
```

#### 核心算法实现

**智能记忆匹配算法**:
```python
def _find_relevant_memories_by_message(self, memories: List[MemoryEntry], user_message: str) -> List[MemoryEntry]:
    """根据用户消息智能选择相关记忆"""
    if not user_message or not memories:
        return []
    
    # 1. 提取关键词
    message_keywords = self._extract_keywords_from_message(user_message.lower())
    
    # 2. 如果没有提取到关键词，说明消息与技术内容无关
    if not message_keywords:
        return []
    
    # 3. 使用批量评分优化
    if self.enable_optimized_scoring and self._optimized_scoring_engine:
        try:
            batch_results = self._optimized_scoring_engine.batch_calculate_scores(
                user_message.lower(), 
                memories, 
                max_workers=4
            )
            
            scored_memories = []
            for memory_id, score, details in batch_results:
                if score >= 10.0:  # 相关性阈值
                    memory = next((m for m in memories if m.id == memory_id), None)
                    if memory:
                        scored_memories.append((memory, score))
                        
        except Exception as e:
            # 回退到标准评分
            scored_memories = self._calculate_individual_scores(memories, message_keywords, user_message.lower())
    else:
        scored_memories = self._calculate_individual_scores(memories, message_keywords, user_message.lower())
    
    # 4. 按相关性分数和重要性排序
    scored_memories.sort(key=lambda x: (x[1], x[0].importance), reverse=True)
    
    return [memory for memory, score in scored_memories]
```

**多维度评分机制**:
```python
def _calculate_memory_relevance_score(self, memory: MemoryEntry, message_keywords: List[str], full_message: str) -> float:
    """计算记忆与用户消息的相关性分数"""
    score = 0.0
    
    # 1. 标签匹配 (权重: 3.0)
    for tag in memory.tags:
        tag_lower = tag.lower()
        for keyword in message_keywords:
            if keyword in tag_lower or tag_lower in keyword:
                score += 3.0
    
    # 2. 内容关键词匹配 (权重: 2.0)
    memory_content_lower = memory.content.lower()
    for keyword in message_keywords:
        if keyword in memory_content_lower:
            score += 2.0
    
    # 3. 项目名匹配 (权重: 1.5)
    if memory.project and memory.project.lower() != 'general':
        project_lower = memory.project.lower()
        for keyword in message_keywords:
            if keyword in project_lower or project_lower in keyword:
                score += 1.5
    
    # 4. 完整短语匹配 (权重: 4.0)
    for i in range(len(message_keywords) - 1):
        phrase = " ".join(message_keywords[i:i+2])
        if phrase in memory_content_lower:
            score += 4.0
    
    # 5. 语义相关性匹配 (权重: 1.5倍)
    semantic_score = self._calculate_semantic_relevance(memory, message_keywords, full_message)
    score += semantic_score * 1.5
    
    # 6. 重要性加权
    score *= (memory.importance / 3.0)
    
    return score
```

#### 语义相关性算法

```python
def _calculate_semantic_relevance(self, memory: MemoryEntry, message_keywords: List[str], full_message: str) -> float:
    """计算语义相关性得分 - 基于通用语义匹配原则"""
    semantic_score = 0.0
    memory_text = memory.content.lower() + ' ' + ' '.join(memory.tags).lower()
    
    # 1. 领域概念密度评分 (0-10分)
    domain_keywords = ['api', 'workflow', 'solution', 'rule', 'step', 'validation', 'model']
    user_domain_concepts = [kw for kw in message_keywords if kw in domain_keywords]
    memory_domain_matches = sum(1 for concept in user_domain_concepts if concept in memory_text)
    
    if user_domain_concepts:
        domain_density = (memory_domain_matches / len(user_domain_concepts)) * 10
        semantic_score += domain_density
    
    # 2. 问题-解决方案匹配度 (0-15分)
    problem_solution_pairs = [
        (['enhance', 'improve', 'add', 'support'], ['design', 'architecture', 'implementation', 'approach']),
        (['validate', 'check', 'ensure'], ['validation', 'verification', 'logic', 'mechanism']),
        (['reference', 'link', 'connect'], ['relationship', 'mapping', 'association', 'routing']),
        (['create', 'build', 'generate'], ['creation', 'construction', 'generation', 'workflow'])
    ]
    
    for problem_words, solution_words in problem_solution_pairs:
        has_problem = any(word in message_keywords for word in problem_words)
        has_solution = any(word in memory_text for word in solution_words)
        if has_problem and has_solution:
            semantic_score += 3.0
    
    # 3. 复合概念匹配 (0-20分)
    import re
    user_phrases = re.findall(r'[a-z]+(?:\s+[a-z]+){1,2}', full_message.lower())
    
    concept_mappings = [
        (['solution as step', 'solution.*step'], ['orderedsteps', 'step.*solution', 'list.*string']),
        (['solution reference', 'solution.*id'], ['id.*prefix', 'prefix.*identification', 's_.*uuid']),
        (['validate.*solution', 'ensure.*valid'], ['validation.*logic', 'exist.*rule', 'prompt.*exist']),
        (['workflow creation', 'creating workflow'], ['create.*workflow', 'workflow.*design', 'api.*design'])
    ]
    
    for user_patterns, memory_patterns in concept_mappings:
        user_match = any(re.search(pattern, full_message.lower()) for pattern in user_patterns)
        memory_match = any(re.search(pattern, memory_text) for pattern in memory_patterns)
        
        if user_match and memory_match:
            semantic_score += 4.0
    
    return semantic_score
```

### 2. 自学习评分引擎 (SelfLearningMemoryScoringEngine)

#### 关键词矩阵数据结构

```python
@dataclass
class KeywordInfo:
    """关键词信息"""
    weight: float = 1.0
    usage_count: int = 0
    total_score_contribution: float = 0.0
    last_updated: str = ""
    confidence_level: float = 0.5
    stability_score: float = 0.0
    learning_rate: float = 0.05

@dataclass  
class SelfLearningKeywordMatrix:
    """自学习关键词矩阵"""
    dimensions: Dict[str, Dict[str, KeywordInfo]] = field(default_factory=dict)
    learning_rate: float = 0.05
    stabilization_threshold: int = 20
    keyword_discovery_threshold: float = 0.7
    version: str = "1.0"
    last_learning_session: str = ""
    total_learning_sessions: int = 0
    discovered_keywords_count: int = 0
```

#### 自动关键词发现算法

```python
def discover_keywords_from_requirement(self, requirement: str) -> Dict[str, Dict[str, float]]:
    """从需求中自动发现新关键词"""
    discovered = defaultdict(lambda: defaultdict(float))
    
    # 1. 技术词汇模式识别
    tech_patterns = [
        (r'[A-Z][a-z]+(?:[A-Z][a-z]+)+', 'technical'),  # CamelCase
        (r'[a-z]+-[a-z]+(?:-[a-z]+)*', 'technical'),    # kebab-case
        (r'[a-z]+_[a-z]+(?:_[a-z]+)*', 'technical'),    # snake_case
        (r'[A-Z]{2,}', 'technical'),                     # 缩写
        (r'\b[a-z]+(?:Service|Controller|Manager|Engine|Factory|Builder|Handler)\b', 'architectural'),
        (r'\b[a-z]+(?:API|Http|Rest|Json|Xml|Sql)\b', 'technical'),
    ]
    
    for pattern, dimension in tech_patterns:
        matches = re.findall(pattern, requirement, re.IGNORECASE)
        for match in matches:
            keyword = match.lower()
            if self._is_valid_keyword(keyword):
                confidence = self._calculate_discovery_confidence(keyword, requirement, dimension)
                if confidence >= self.keyword_discovery_threshold:
                    discovered[dimension][keyword] = confidence
    
    # 2. 基于上下文的关键词发现
    context_keywords = self._discover_contextual_keywords(requirement)
    for dimension, keywords in context_keywords.items():
        discovered[dimension].update(keywords)
    
    return dict(discovered)

def _calculate_discovery_confidence(self, keyword: str, context: str, dimension: str) -> float:
    """计算关键词发现的置信度"""
    confidence = 0.0
    
    # 基础置信度
    if len(keyword) >= 3:
        confidence += 0.3
    
    # 技术术语加分
    if any(tech in keyword.lower() for tech in ['api', 'service', 'data', 'system', 'manage']):
        confidence += 0.2
    
    # 上下文相关性
    context_words = context.lower().split()
    if keyword in context_words:
        confidence += 0.3
    
    # 词频加分
    word_freq = context.lower().count(keyword)
    if word_freq > 1:
        confidence += min(0.2, word_freq * 0.05)
    
    return min(1.0, confidence)
```

#### 权重自适应调整算法

```python
def _adjust_keyword_weights(self, scored_memories: List['MemoryScore']):
    """基于评分结果自适应调整关键词权重"""
    
    for memory_score in scored_memories:
        for dimension, score_info in memory_score.score_breakdown.items():
            if dimension not in self.keyword_matrix.dimensions:
                continue
                
            dimension_keywords = self.keyword_matrix.dimensions[dimension]
            matched_keywords = score_info.get('matched_keywords', {})
            
            for keyword, contribution in matched_keywords.items():
                if keyword in dimension_keywords:
                    keyword_info = dimension_keywords[keyword]
                    
                    # 更新使用统计
                    keyword_info.usage_count += 1
                    keyword_info.total_score_contribution += contribution
                    keyword_info.last_updated = datetime.now().isoformat()
                    
                    # 计算稳定性因子
                    stability_factor = self._calculate_stability_factor(keyword_info)
                    
                    # 计算性能因子
                    avg_contribution = keyword_info.total_score_contribution / keyword_info.usage_count
                    performance_factor = self._calculate_performance_factor(avg_contribution)
                    
                    # 自适应权重调整
                    if keyword_info.usage_count < self.keyword_matrix.stabilization_threshold:
                        # 学习期：积极调整
                        adjustment = self.keyword_matrix.learning_rate * stability_factor * performance_factor
                        keyword_info.weight = max(0.1, min(2.0, keyword_info.weight + adjustment))
                    else:
                        # 稳定期：保守调整
                        adjustment = self.keyword_matrix.learning_rate * 0.1 * performance_factor
                        keyword_info.weight = max(0.5, min(1.5, keyword_info.weight + adjustment))
                    
                    # 更新稳定性分数
                    keyword_info.stability_score = self._calculate_stability_score(keyword_info)

def _calculate_stability_factor(self, keyword_info: KeywordInfo) -> float:
    """计算稳定性因子"""
    usage_ratio = min(1.0, keyword_info.usage_count / self.keyword_matrix.stabilization_threshold)
    
    if keyword_info.usage_count < self.keyword_matrix.stabilization_threshold:
        return 1.0 + (self.keyword_matrix.learning_rate * usage_ratio)
    else:
        return 1.0 + (self.keyword_matrix.learning_rate * 0.1)

def _calculate_performance_factor(self, avg_contribution: float) -> float:
    """计算性能因子"""
    if avg_contribution > 0.8:
        return 1.1  # 高性能关键词
    elif avg_contribution < 0.3:
        return 0.9  # 低性能关键词
    else:
        return 1.0  # 一般性能
```

### 3. 优化评分引擎 (OptimizedScoringEngine)

#### 批量并行处理实现

```python
def batch_calculate_scores(self, user_message: str, memories: List[MemoryEntry], max_workers: int = 4) -> List[Tuple]:
    """批量并行计算评分"""
    import concurrent.futures
    import hashlib
    
    def calculate_single_score(memory):
        try:
            # 生成缓存键
            cache_key = self._generate_cache_key(user_message, memory.id)
            
            # 检查缓存
            if cache_key in self.score_cache:
                self.cache_hits += 1
                return memory.id, self.score_cache[cache_key], {'cached': True}
            
            # 计算新评分
            start_time = time.time()
            score, details = self.calculate_memory_score(user_message, memory)
            end_time = time.time()
            
            # 更新性能统计
            self.total_calculations += 1
            self.total_calculation_time += (end_time - start_time)
            
            # 更新缓存
            self.score_cache[cache_key] = score
            if len(self.score_cache) > self.max_cache_size:
                self._cleanup_cache()
            
            details['cached'] = False
            details['calculation_time'] = end_time - start_time
            
            return memory.id, score, details
            
        except Exception as e:
            self.calculation_errors += 1
            return memory.id, 0.0, {'error': str(e)}
    
    # 并行处理
    start_time = time.time()
    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
        results = list(executor.map(calculate_single_score, memories))
    
    # 更新批量处理统计
    processing_time = time.time() - start_time
    self.batch_processing_times.append(processing_time)
    
    return results

def _generate_cache_key(self, user_message: str, memory_id: str) -> str:
    """生成缓存键"""
    import hashlib
    content = f"{user_message}:{memory_id}"
    return hashlib.md5(content.encode()).hexdigest()

def _cleanup_cache(self):
    """清理缓存，保留最近使用的条目"""
    if len(self.score_cache) > self.max_cache_size:
        # 简单的LRU策略：删除最老的一半条目
        cache_items = list(self.score_cache.items())
        keep_count = self.max_cache_size // 2
        self.score_cache = dict(cache_items[-keep_count:])
```

#### 性能监控实现

```python
def get_performance_stats(self) -> Dict:
    """获取性能统计信息"""
    total_requests = self.cache_hits + self.total_calculations
    
    return {
        'cache_hit_rate': self.cache_hits / total_requests if total_requests > 0 else 0,
        'total_calculations': self.total_calculations,
        'cache_hits': self.cache_hits,
        'calculation_errors': self.calculation_errors,
        'avg_response_time': self.total_calculation_time / self.total_calculations if self.total_calculations > 0 else 0,
        'avg_batch_time': sum(self.batch_processing_times) / len(self.batch_processing_times) if self.batch_processing_times else 0,
        'cache_size': len(self.score_cache),
        'max_cache_size': self.max_cache_size
    }
```

### 4. System Prompt生成器 (SystemPromptGenerator)

#### 核心生成逻辑

```python
def generate_system_prompt(self, user_message: str, team_name: str, mode: str = "hybrid", **kwargs) -> Dict[str, Any]:
    """生成系统提示词"""
    try:
        # 1. 参数验证和预处理
        available_teams = self.get_available_teams()
        if team_name not in available_teams:
            return {
                "success": False,
                "error": f"团队 '{team_name}' 不存在。可用团队: {available_teams}",
                "available_teams": available_teams
            }
        
        # 2. 调用团队上下文命令生成上下文
        result = self.context_command.execute(
            team_name=team_name,
            action="generate",
            mode=mode,
            stages=kwargs.get('stages', 'all'),
            memory_types=kwargs.get('memory_types', 'all'),
            output_format="json",
            save_results=kwargs.get('save_results', False),
            project_scope=kwargs.get('project_scope'),
            memory_importance=kwargs.get('memory_importance', 2),
            max_memory_items=kwargs.get('max_memory_items', 50),
            tags_filter=kwargs.get('tags_filter'),
            user_message=user_message
        )
        
        if not result.success:
            return {
                "success": False,
                "error": f"上下文生成失败: {result.error or result.message}",
                "team_name": team_name,
                "mode": mode
            }
        
        # 3. 提取和处理生成的内容
        system_prompt = self._extract_system_prompt_content(result)
        
        # 4. 保存结果
        saved_file_path = self._save_system_prompt(
            system_prompt=system_prompt,
            team_name=team_name,
            mode=mode,
            user_message=user_message
        )
        
        # 5. 构建返回结果
        generation_result = {
            "success": True,
            "system_prompt": system_prompt,
            "system_prompt_length": len(system_prompt),
            "team_name": team_name,
            "mode": mode,
            "user_message": user_message,
            "user_message_length": len(user_message),
            "saved_to": saved_file_path,
            "generation_metadata": {
                "stages": kwargs.get('stages', 'all'),
                "memory_types": kwargs.get('memory_types', 'all'),
                "project_scope": kwargs.get('project_scope'),
                "memory_importance": kwargs.get('memory_importance', 2),
                "max_memory_items": kwargs.get('max_memory_items', 50),
                "tags_filter": kwargs.get('tags_filter'),
                "learning_enabled": self._learning_enabled
            }
        }
        
        # 6. 学习机制处理
        matched_memories = self._extract_matched_memories(result)
        self._record_generation_session(team_name, user_message, generation_result, matched_memories)
        
        if self._learning_enabled and matched_memories:
            self._perform_lightweight_learning(team_name, user_message, matched_memories, kwargs.get('verbose', False))
        
        return generation_result
        
    except Exception as e:
        return {
            "success": False,
            "error": str(e),
            "team_name": team_name,
            "mode": mode,
            "user_message": user_message
        }
```

#### 学习机制实现

```python
def _perform_lightweight_learning(self, team_name: str, user_message: str, matched_memories: list, verbose: bool = False):
    """执行轻量级学习（不立即更新权重，仅记录统计）"""
    try:
        scoring_engine_info = self._get_scoring_engine(team_name)
        if not scoring_engine_info:
            return
        
        scoring_engine = scoring_engine_info['engine']
        
        # 创建虚拟记忆项目用于统计更新
        from src.scoring_self_evolution import MemoryItem
        
        mock_memories = []
        for i, memory_id in enumerate(matched_memories[:5]):  # 限制最多5个
            mock_memory = MemoryItem(
                id=memory_id,
                title=f"System Prompt Matched Memory {i+1}",
                content=f"Memory matched for: {user_message[:100]}",
                tags=["system_prompt", "matched"],
                project="system_prompt_generation",
                importance=3
            )
            mock_memories.append(mock_memory)
        
        if mock_memories:
            # 执行轻量级评分（主要为了统计更新）
            results = scoring_engine.score_memory_items(user_message, mock_memories)
            
            # 保存更新后的矩阵
            matrix_file = scoring_engine_info['matrix_file']
            scoring_engine.save_matrix(str(matrix_file))
            
            if verbose:
                print(f"🎓 轻量级学习完成 - 更新了{len(matched_memories)}个记忆的统计信息")
                
    except Exception as e:
        if verbose:
            print(f"⚠️ 轻量级学习失败: {e}")

def provide_usage_feedback(self, team_name: str, user_message: str, system_prompt_effectiveness: int, **kwargs) -> Dict[str, Any]:
    """提供System Prompt使用效果反馈，触发深度学习"""
    if not self._learning_enabled:
        return {"success": False, "message": "学习机制未启用"}
    
    try:
        scoring_engine_info = self._get_scoring_engine(team_name)
        if not scoring_engine_info:
            return {"success": False, "message": "评分引擎不可用"}
        
        scoring_engine = scoring_engine_info['engine']
        matched_memories = kwargs.get('matched_memories', [])
        comment = kwargs.get('comment', '')
        
        # 为每个匹配的记忆添加反馈
        feedback_count = 0
        if matched_memories:
            for memory_id in matched_memories:
                scoring_engine.add_user_feedback(
                    memory_id=memory_id,
                    query=user_message,
                    rating=system_prompt_effectiveness,
                    matched_keywords=[],
                    comment=f"System Prompt feedback: {comment}"
                )
                feedback_count += 1
        
        # 保存学习结果
        matrix_file = scoring_engine_info['matrix_file']
        scoring_engine.save_matrix(str(matrix_file))
        
        return {
            "success": True,
            "message": f"反馈已记录，更新了{feedback_count}个记忆的学习数据",
            "feedback_count": feedback_count,
            "effectiveness_rating": system_prompt_effectiveness
        }
        
    except Exception as e:
        return {"success": False, "message": f"反馈处理失败: {e}"}
```

### 5. 七步框架引擎 (SevenStageEngine)

#### 框架模板加载机制

```python
class SevenStageEngine:
    """七步框架引擎"""
    
    def __init__(self, framework_path: Path):
        self.framework_path = framework_path
        self.stage_files = {
            "overview": "00_overview.md",
            "requirements": "01_requirements.md", 
            "business-model": "02_business_model.md",
            "solution": "03_solution.md",
            "structure": "04_structure.md",
            "tasks": "05_tasks.md",
            "common-tasks": "06_common_tasks.md",
            "constraints": "07_constraints.md"
        }
        
    def load_framework_content(self, stages: List[str]) -> Dict[str, str]:
        """加载框架内容"""
        content = {}
        
        # 始终包含概述
        overview_content = self._load_stage_content("overview")
        if overview_content:
            content["overview"] = overview_content
        
        # 按顺序加载指定阶段
        stage_order = ["requirements", "business-model", "solution", "structure", "tasks", "common-tasks", "constraints"]
        
        for stage in stage_order:
            if stage in stages:
                stage_content = self._load_stage_content(stage)
                if stage_content:
                    content[stage] = stage_content
        
        return content
    
    def _load_stage_content(self, stage: str) -> Optional[str]:
        """加载单个阶段内容"""
        if stage not in self.stage_files:
            return None
            
        stage_file = self.framework_path / self.stage_files[stage]
        if stage_file.exists():
            return stage_file.read_text(encoding='utf-8')
        return None
    
    def validate_stage_sequence(self, stages: List[str]) -> Dict[str, Any]:
        """验证阶段序列的完整性和逻辑性"""
        stage_order = ["requirements", "business-model", "solution", "structure", "tasks", "common-tasks", "constraints"]
        
        # 检查阶段顺序
        ordered_stages = [s for s in stage_order if s in stages]
        
        # 检查关键依赖
        validation_result = {
            "valid": True,
            "warnings": [],
            "errors": [],
            "suggested_order": ordered_stages
        }
        
        # 验证关键依赖关系
        if "solution" in stages and "requirements" not in stages:
            validation_result["warnings"].append("解决方案阶段建议包含需求锚定阶段")
        
        if "structure" in stages and "solution" not in stages:
            validation_result["warnings"].append("结构定义阶段建议包含解决方案阶段")
        
        if "tasks" in stages and "structure" not in stages:
            validation_result["warnings"].append("任务编排阶段建议包含结构定义阶段")
        
        return validation_result
```

### 6. 目录管理器 (DirectoryManager)

#### 团队和项目结构管理

```python
class DirectoryManager:
    """目录管理器"""
    
    def __init__(self, base_path: Path):
        self.base_path = Path(base_path)
        self.teams_path = self.base_path / "teams"
        
    def create_team(self, team_name: str, description: str = "") -> Path:
        """创建团队目录结构"""
        team_path = self.teams_path / team_name
        
        if team_path.exists():
            raise ValueError(f"团队 '{team_name}' 已存在")
        
        # 创建团队目录结构
        directories = [
            team_path,
            team_path / "memory",
            team_path / "memory" / "episodic", 
            team_path / "context",
            team_path / "projects"
        ]
        
        for directory in directories:
            directory.mkdir(parents=True, exist_ok=True)
        
        # 创建初始文件
        self._create_initial_memory_files(team_path)
        self._create_team_metadata(team_path, team_name, description)
        
        return team_path
    
    def create_project(self, team_name: str, project_name: str, description: str = "") -> Path:
        """创建项目目录结构"""
        team_path = self.get_team_path(team_name)
        if not team_path.exists():
            raise ValueError(f"团队 '{team_name}' 不存在")
        
        project_path = team_path / "projects" / project_name
        
        if project_path.exists():
            raise ValueError(f"项目 '{project_name}' 已存在")
        
        # 创建项目目录结构
        directories = [
            project_path,
            project_path / "memory",
            project_path / "memory" / "episodic",
            project_path / "context"
        ]
        
        for directory in directories:
            directory.mkdir(parents=True, exist_ok=True)
            
        # 创建初始文件
        self._create_initial_memory_files(project_path)
        self._create_project_metadata(project_path, project_name, description)
        
        return project_path
    
    def _create_initial_memory_files(self, base_path: Path):
        """创建初始记忆文件"""
        memory_path = base_path / "memory"
        
        # 创建程序性记忆文件
        procedural_file = memory_path / "procedural.md"
        if not procedural_file.exists():
            procedural_content = f"""# 团队记忆：{base_path.name.title()}

## 元数据
- **团队**: {base_path.name}
- **创建时间**: {datetime.now().isoformat()}
- **最后更新**: {datetime.now().isoformat()}
- **记忆类型**: procedural

## 记忆条目

<!-- 在这里添加程序性记忆条目 -->
"""
            procedural_file.write_text(procedural_content, encoding='utf-8')
        
        # 创建声明性记忆文件
        declarative_file = memory_path / "declarative.md"
        if not declarative_file.exists():
            declarative_content = f"""# 团队声明性记忆：{base_path.name.title()}

## 元数据
- **团队**: {base_path.name}  
- **创建时间**: {datetime.now().isoformat()}
- **最后更新**: {datetime.now().isoformat()}
- **记忆类型**: declarative

## 记忆条目

<!-- 在这里添加声明性记忆条目 -->
"""
            declarative_file.write_text(declarative_content, encoding='utf-8')
    
    def get_memory_path(self, team_name: str, memory_type: str, project_name: str = None) -> Path:
        """获取记忆文件路径"""
        if project_name:
            base_path = self.teams_path / team_name / "projects" / project_name
        else:
            base_path = self.teams_path / team_name
            
        if memory_type == "episodic":
            return base_path / "memory" / "episodic"
        else:
            return base_path / "memory" / f"{memory_type}.md"
```

## 🔄 数据流实现

### 记忆检索数据流

```python
def _load_team_memories(self, team_path: Path, config: ContextGenerationConfig) -> List[MemoryEntry]:
    """加载团队或项目记忆"""
    memories = []
    
    # 确定要加载的记忆类型
    memory_types_to_load = config.include_memory_types
    if MemoryType.ALL in memory_types_to_load:
        memory_types_to_load = [MemoryType.DECLARATIVE, MemoryType.PROCEDURAL, MemoryType.EPISODIC]
    
    # 优先加载项目级别的记忆
    if config.project_name:
        project_path = team_path / "projects" / config.project_name
        if project_path.exists():
            project_memories = self._load_memories_from_path(project_path, memory_types_to_load, f"project:{config.project_name}")
            memories.extend(project_memories)
    
    # 加载团队级别的记忆
    if config.include_team_memories or not config.project_name:
        team_memories = self._load_memories_from_path(team_path, memory_types_to_load, "team")
        memories.extend(team_memories)
    
    # 去重：基于记忆ID去除重复项，保留第一个（项目记忆优先）
    seen_ids = set()
    unique_memories = []
    for memory in memories:
        if memory.id not in seen_ids:
            seen_ids.add(memory.id)
            unique_memories.append(memory)
    
    # 应用过滤器
    filtered_memories = self._apply_memory_filters(unique_memories, config)
    
    # 排序：按重要性和时间排序
    filtered_memories.sort(key=lambda m: (m.importance, m.timestamp), reverse=True)
    
    # 限制数量
    return filtered_memories[:config.max_memory_items]
```

### 上下文组装数据流

```python
def _generate_hybrid_context(self, config: ContextGenerationConfig, team_path: Path, user_message: str = None) -> GeneratedContext:
    """生成混合模式上下文（记忆+框架）"""
    memories = self._load_team_memories(team_path, config)
    
    content_sections = []
    used_memory_ids = set()
    
    # 1. 添加混合模式指导提示
    content_sections.extend([
        "先理解记忆的内容，再基于七步框架结合user_message生成具体的结构化提示词",
        "",
        "---",
        ""
    ])
    
    # 2. 智能选择和添加相关记忆
    if memories and user_message:
        relevant_memories = self._find_relevant_memories_by_message(memories, user_message)
        if relevant_memories:
            top_memories = relevant_memories[:5]  # 限制最多5个最相关的记忆
            for memory in top_memories:
                content_sections.extend([
                    f"#团队记忆",
                    f"### {memory.id}",
                    f"**Project:** {memory.project}",
                    f"**Importance:** {'⭐' * memory.importance}",
                    f"**Tags:** {', '.join(memory.tags)}",
                    "",
                    memory.content,
                    "",
                    "---",
                    ""
                ])
                used_memory_ids.add(memory.id)
    
    # 3. 加载和组装七阶段框架
    content_sections.extend([
        "# 七步框架模板内容",
        "",
        ""
    ])
    
    included_stages = []
    for stage in config.include_framework_stages:
        stage_content = self._load_framework_stage(stage)
        if stage_content:
            included_stages.append(stage)
            content_sections.extend([stage_content, ""])
            
            # 加载项目或团队自定义上下文
            context_content = self._load_context_file(team_path, stage, config)
            if context_content and context_content.strip():
                content_sections.extend([context_content, ""])
            
            content_sections.extend(["---", ""])
    
    return GeneratedContext(
        team_name=config.team_name,
        mode=config.mode,
        content="\n".join(content_sections),
        source_memories=list(used_memory_ids),
        framework_stages=included_stages,
        metadata={
            'memory_count': len(used_memory_ids),
            'total_memories_available': len(memories),
            'framework_stages_count': len(included_stages),
            'hybrid_mode': True
        }
    )
```

## ⚡ 性能优化实现

### 缓存机制

```python
class CacheManager:
    """缓存管理器"""
    
    def __init__(self, max_size: int = 1000):
        self.max_size = max_size
        self.cache = {}
        self.access_times = {}
        self.hit_count = 0
        self.miss_count = 0
    
    def get(self, key: str) -> Optional[Any]:
        """获取缓存值"""
        if key in self.cache:
            self.access_times[key] = time.time()
            self.hit_count += 1
            return self.cache[key]
        else:
            self.miss_count += 1
            return None
    
    def put(self, key: str, value: Any):
        """存储缓存值"""
        if len(self.cache) >= self.max_size:
            self._evict_lru()
        
        self.cache[key] = value
        self.access_times[key] = time.time()
    
    def _evict_lru(self):
        """LRU淘汰策略"""
        if not self.access_times:
            return
            
        # 找到最少最近使用的key
        lru_key = min(self.access_times.keys(), key=lambda k: self.access_times[k])
        
        # 删除
        del self.cache[lru_key]
        del self.access_times[lru_key]
    
    def get_stats(self) -> Dict:
        """获取缓存统计"""
        total_requests = self.hit_count + self.miss_count
        return {
            'hit_rate': self.hit_count / total_requests if total_requests > 0 else 0,
            'hit_count': self.hit_count,
            'miss_count': self.miss_count,
            'cache_size': len(self.cache),
            'max_size': self.max_size
        }
```

### 并发处理

```python
import asyncio
import concurrent.futures
from typing import Awaitable

async def async_batch_process_memories(memories: List[MemoryEntry], user_message: str, max_concurrent: int = 10) -> List[Tuple]:
    """异步批量处理记忆评分"""
    
    semaphore = asyncio.Semaphore(max_concurrent)
    
    async def process_single_memory(memory: MemoryEntry) -> Tuple:
        async with semaphore:
            # 在线程池中执行CPU密集型的评分计算
            loop = asyncio.get_event_loop()
            with concurrent.futures.ThreadPoolExecutor() as executor:
                future = executor.submit(calculate_memory_score, user_message, memory)
                score, details = await loop.run_in_executor(None, future.result)
                return memory.id, score, details
    
    # 创建所有任务
    tasks = [process_single_memory(memory) for memory in memories]
    
    # 并发执行所有任务
    results = await asyncio.gather(*tasks, return_exceptions=True)
    
    # 处理异常结果
    clean_results = []
    for result in results:
        if isinstance(result, Exception):
            print(f"处理记忆时出错: {result}")
        else:
            clean_results.append(result)
    
    return clean_results
```

## 🔒 错误处理实现

### 异常层次结构

```python
class ContextManagementError(Exception):
    """上下文管理基础异常"""
    pass

class TeamNotFoundError(ContextManagementError):
    """团队不存在异常"""
    def __init__(self, team_name: str, available_teams: List[str]):
        self.team_name = team_name
        self.available_teams = available_teams
        super().__init__(f"团队 '{team_name}' 不存在。可用团队: {available_teams}")

class MemoryLoadError(ContextManagementError):
    """记忆加载异常"""
    def __init__(self, memory_path: str, cause: Exception):
        self.memory_path = memory_path
        self.cause = cause
        super().__init__(f"加载记忆文件 '{memory_path}' 失败: {cause}")

class ScoringEngineError(ContextManagementError):
    """评分引擎异常"""
    pass

class APIConnectionError(ContextManagementError):
    """API连接异常"""
    def __init__(self, api_name: str, cause: Exception):
        self.api_name = api_name
        self.cause = cause
        super().__init__(f"{api_name} API调用失败: {cause}")
```

### 错误处理装饰器

```python
def handle_context_errors(func):
    """上下文处理错误处理装饰器"""
    def wrapper(*args, **kwargs):
        try:
            return func(*args, **kwargs)
        except TeamNotFoundError as e:
            return {
                "success": False,
                "error_type": "team_not_found",
                "error": str(e),
                "available_teams": e.available_teams
            }
        except MemoryLoadError as e:
            return {
                "success": False,
                "error_type": "memory_load_error", 
                "error": str(e),
                "memory_path": e.memory_path
            }
        except APIConnectionError as e:
            return {
                "success": False,
                "error_type": "api_connection_error",
                "error": str(e),
                "api_name": e.api_name
            }
        except Exception as e:
            return {
                "success": False,
                "error_type": "unknown_error",
                "error": str(e)
            }
    return wrapper
```

这些实现细节展示了系统各个核心模块的具体实现方式，包括数据结构设计、算法实现、性能优化策略和错误处理机制，为理解和维护系统提供了详细的技术参考。