# å®ç°ç»†èŠ‚æ–‡æ¡£

## ğŸ”§ æ ¸å¿ƒæ¨¡å—å®ç°

### 1. ä¸Šä¸‹æ–‡å¤„ç†å™¨ (ContextProcessor)

#### æ ¸å¿ƒæ•°æ®ç»“æ„

```python
@dataclass
class ContextGenerationConfig:
    """ä¸Šä¸‹æ–‡ç”Ÿæˆé…ç½®"""
    team_name: str
    project_name: Optional[str] = None
    mode: ContextMode = ContextMode.HYBRID
    
    # è®°å¿†ç›¸å…³é…ç½®
    include_memory_types: List[MemoryType] = field(default_factory=lambda: [MemoryType.ALL])
    max_memory_items: int = 50
    memory_importance_threshold: int = 2
    include_team_memories: bool = True
    
    # æ¡†æ¶ç›¸å…³é…ç½®
    include_framework_stages: List[str] = field(default_factory=lambda: [
        "requirements", "business-model", "solution", "structure", 
        "tasks", "common-tasks", "constraints"
    ])
    
    # è¿‡æ»¤æ¡ä»¶
    project_scope: Optional[str] = None
    time_range: Optional[Tuple[str, str]] = None
    memory_filters: Dict[str, Any] = field(default_factory=dict)

@dataclass  
class GeneratedContext:
    """ç”Ÿæˆçš„ä¸Šä¸‹æ–‡ç»“æœ"""
    team_name: str
    mode: ContextMode
    content: str
    source_memories: List[str] = field(default_factory=list)
    framework_stages: List[str] = field(default_factory=list)
    metadata: Dict[str, Any] = field(default_factory=dict)
    generation_time: str = field(default_factory=lambda: datetime.now().isoformat())
```

#### æ ¸å¿ƒç®—æ³•å®ç°

**æ™ºèƒ½è®°å¿†åŒ¹é…ç®—æ³•**:
```python
def _find_relevant_memories_by_message(self, memories: List[MemoryEntry], user_message: str) -> List[MemoryEntry]:
    """æ ¹æ®ç”¨æˆ·æ¶ˆæ¯æ™ºèƒ½é€‰æ‹©ç›¸å…³è®°å¿†"""
    if not user_message or not memories:
        return []
    
    # 1. æå–å…³é”®è¯
    message_keywords = self._extract_keywords_from_message(user_message.lower())
    
    # 2. å¦‚æœæ²¡æœ‰æå–åˆ°å…³é”®è¯ï¼Œè¯´æ˜æ¶ˆæ¯ä¸æŠ€æœ¯å†…å®¹æ— å…³
    if not message_keywords:
        return []
    
    # 3. ä½¿ç”¨æ‰¹é‡è¯„åˆ†ä¼˜åŒ–
    if self.enable_optimized_scoring and self._optimized_scoring_engine:
        try:
            batch_results = self._optimized_scoring_engine.batch_calculate_scores(
                user_message.lower(), 
                memories, 
                max_workers=4
            )
            
            scored_memories = []
            for memory_id, score, details in batch_results:
                if score >= 10.0:  # ç›¸å…³æ€§é˜ˆå€¼
                    memory = next((m for m in memories if m.id == memory_id), None)
                    if memory:
                        scored_memories.append((memory, score))
                        
        except Exception as e:
            # å›é€€åˆ°æ ‡å‡†è¯„åˆ†
            scored_memories = self._calculate_individual_scores(memories, message_keywords, user_message.lower())
    else:
        scored_memories = self._calculate_individual_scores(memories, message_keywords, user_message.lower())
    
    # 4. æŒ‰ç›¸å…³æ€§åˆ†æ•°å’Œé‡è¦æ€§æ’åº
    scored_memories.sort(key=lambda x: (x[1], x[0].importance), reverse=True)
    
    return [memory for memory, score in scored_memories]
```

**å¤šç»´åº¦è¯„åˆ†æœºåˆ¶**:
```python
def _calculate_memory_relevance_score(self, memory: MemoryEntry, message_keywords: List[str], full_message: str) -> float:
    """è®¡ç®—è®°å¿†ä¸ç”¨æˆ·æ¶ˆæ¯çš„ç›¸å…³æ€§åˆ†æ•°"""
    score = 0.0
    
    # 1. æ ‡ç­¾åŒ¹é… (æƒé‡: 3.0)
    for tag in memory.tags:
        tag_lower = tag.lower()
        for keyword in message_keywords:
            if keyword in tag_lower or tag_lower in keyword:
                score += 3.0
    
    # 2. å†…å®¹å…³é”®è¯åŒ¹é… (æƒé‡: 2.0)
    memory_content_lower = memory.content.lower()
    for keyword in message_keywords:
        if keyword in memory_content_lower:
            score += 2.0
    
    # 3. é¡¹ç›®ååŒ¹é… (æƒé‡: 1.5)
    if memory.project and memory.project.lower() != 'general':
        project_lower = memory.project.lower()
        for keyword in message_keywords:
            if keyword in project_lower or project_lower in keyword:
                score += 1.5
    
    # 4. å®Œæ•´çŸ­è¯­åŒ¹é… (æƒé‡: 4.0)
    for i in range(len(message_keywords) - 1):
        phrase = " ".join(message_keywords[i:i+2])
        if phrase in memory_content_lower:
            score += 4.0
    
    # 5. è¯­ä¹‰ç›¸å…³æ€§åŒ¹é… (æƒé‡: 1.5å€)
    semantic_score = self._calculate_semantic_relevance(memory, message_keywords, full_message)
    score += semantic_score * 1.5
    
    # 6. é‡è¦æ€§åŠ æƒ
    score *= (memory.importance / 3.0)
    
    return score
```

#### è¯­ä¹‰ç›¸å…³æ€§ç®—æ³•

```python
def _calculate_semantic_relevance(self, memory: MemoryEntry, message_keywords: List[str], full_message: str) -> float:
    """è®¡ç®—è¯­ä¹‰ç›¸å…³æ€§å¾—åˆ† - åŸºäºé€šç”¨è¯­ä¹‰åŒ¹é…åŸåˆ™"""
    semantic_score = 0.0
    memory_text = memory.content.lower() + ' ' + ' '.join(memory.tags).lower()
    
    # 1. é¢†åŸŸæ¦‚å¿µå¯†åº¦è¯„åˆ† (0-10åˆ†)
    domain_keywords = ['api', 'workflow', 'solution', 'rule', 'step', 'validation', 'model']
    user_domain_concepts = [kw for kw in message_keywords if kw in domain_keywords]
    memory_domain_matches = sum(1 for concept in user_domain_concepts if concept in memory_text)
    
    if user_domain_concepts:
        domain_density = (memory_domain_matches / len(user_domain_concepts)) * 10
        semantic_score += domain_density
    
    # 2. é—®é¢˜-è§£å†³æ–¹æ¡ˆåŒ¹é…åº¦ (0-15åˆ†)
    problem_solution_pairs = [
        (['enhance', 'improve', 'add', 'support'], ['design', 'architecture', 'implementation', 'approach']),
        (['validate', 'check', 'ensure'], ['validation', 'verification', 'logic', 'mechanism']),
        (['reference', 'link', 'connect'], ['relationship', 'mapping', 'association', 'routing']),
        (['create', 'build', 'generate'], ['creation', 'construction', 'generation', 'workflow'])
    ]
    
    for problem_words, solution_words in problem_solution_pairs:
        has_problem = any(word in message_keywords for word in problem_words)
        has_solution = any(word in memory_text for word in solution_words)
        if has_problem and has_solution:
            semantic_score += 3.0
    
    # 3. å¤åˆæ¦‚å¿µåŒ¹é… (0-20åˆ†)
    import re
    user_phrases = re.findall(r'[a-z]+(?:\s+[a-z]+){1,2}', full_message.lower())
    
    concept_mappings = [
        (['solution as step', 'solution.*step'], ['orderedsteps', 'step.*solution', 'list.*string']),
        (['solution reference', 'solution.*id'], ['id.*prefix', 'prefix.*identification', 's_.*uuid']),
        (['validate.*solution', 'ensure.*valid'], ['validation.*logic', 'exist.*rule', 'prompt.*exist']),
        (['workflow creation', 'creating workflow'], ['create.*workflow', 'workflow.*design', 'api.*design'])
    ]
    
    for user_patterns, memory_patterns in concept_mappings:
        user_match = any(re.search(pattern, full_message.lower()) for pattern in user_patterns)
        memory_match = any(re.search(pattern, memory_text) for pattern in memory_patterns)
        
        if user_match and memory_match:
            semantic_score += 4.0
    
    return semantic_score
```

### 2. è‡ªå­¦ä¹ è¯„åˆ†å¼•æ“ (SelfLearningMemoryScoringEngine)

#### å…³é”®è¯çŸ©é˜µæ•°æ®ç»“æ„

```python
@dataclass
class KeywordInfo:
    """å…³é”®è¯ä¿¡æ¯"""
    weight: float = 1.0
    usage_count: int = 0
    total_score_contribution: float = 0.0
    last_updated: str = ""
    confidence_level: float = 0.5
    stability_score: float = 0.0
    learning_rate: float = 0.05

@dataclass  
class SelfLearningKeywordMatrix:
    """è‡ªå­¦ä¹ å…³é”®è¯çŸ©é˜µ"""
    dimensions: Dict[str, Dict[str, KeywordInfo]] = field(default_factory=dict)
    learning_rate: float = 0.05
    stabilization_threshold: int = 20
    keyword_discovery_threshold: float = 0.7
    version: str = "1.0"
    last_learning_session: str = ""
    total_learning_sessions: int = 0
    discovered_keywords_count: int = 0
```

#### è‡ªåŠ¨å…³é”®è¯å‘ç°ç®—æ³•

```python
def discover_keywords_from_requirement(self, requirement: str) -> Dict[str, Dict[str, float]]:
    """ä»éœ€æ±‚ä¸­è‡ªåŠ¨å‘ç°æ–°å…³é”®è¯"""
    discovered = defaultdict(lambda: defaultdict(float))
    
    # 1. æŠ€æœ¯è¯æ±‡æ¨¡å¼è¯†åˆ«
    tech_patterns = [
        (r'[A-Z][a-z]+(?:[A-Z][a-z]+)+', 'technical'),  # CamelCase
        (r'[a-z]+-[a-z]+(?:-[a-z]+)*', 'technical'),    # kebab-case
        (r'[a-z]+_[a-z]+(?:_[a-z]+)*', 'technical'),    # snake_case
        (r'[A-Z]{2,}', 'technical'),                     # ç¼©å†™
        (r'\b[a-z]+(?:Service|Controller|Manager|Engine|Factory|Builder|Handler)\b', 'architectural'),
        (r'\b[a-z]+(?:API|Http|Rest|Json|Xml|Sql)\b', 'technical'),
    ]
    
    for pattern, dimension in tech_patterns:
        matches = re.findall(pattern, requirement, re.IGNORECASE)
        for match in matches:
            keyword = match.lower()
            if self._is_valid_keyword(keyword):
                confidence = self._calculate_discovery_confidence(keyword, requirement, dimension)
                if confidence >= self.keyword_discovery_threshold:
                    discovered[dimension][keyword] = confidence
    
    # 2. åŸºäºä¸Šä¸‹æ–‡çš„å…³é”®è¯å‘ç°
    context_keywords = self._discover_contextual_keywords(requirement)
    for dimension, keywords in context_keywords.items():
        discovered[dimension].update(keywords)
    
    return dict(discovered)

def _calculate_discovery_confidence(self, keyword: str, context: str, dimension: str) -> float:
    """è®¡ç®—å…³é”®è¯å‘ç°çš„ç½®ä¿¡åº¦"""
    confidence = 0.0
    
    # åŸºç¡€ç½®ä¿¡åº¦
    if len(keyword) >= 3:
        confidence += 0.3
    
    # æŠ€æœ¯æœ¯è¯­åŠ åˆ†
    if any(tech in keyword.lower() for tech in ['api', 'service', 'data', 'system', 'manage']):
        confidence += 0.2
    
    # ä¸Šä¸‹æ–‡ç›¸å…³æ€§
    context_words = context.lower().split()
    if keyword in context_words:
        confidence += 0.3
    
    # è¯é¢‘åŠ åˆ†
    word_freq = context.lower().count(keyword)
    if word_freq > 1:
        confidence += min(0.2, word_freq * 0.05)
    
    return min(1.0, confidence)
```

#### æƒé‡è‡ªé€‚åº”è°ƒæ•´ç®—æ³•

```python
def _adjust_keyword_weights(self, scored_memories: List['MemoryScore']):
    """åŸºäºè¯„åˆ†ç»“æœè‡ªé€‚åº”è°ƒæ•´å…³é”®è¯æƒé‡"""
    
    for memory_score in scored_memories:
        for dimension, score_info in memory_score.score_breakdown.items():
            if dimension not in self.keyword_matrix.dimensions:
                continue
                
            dimension_keywords = self.keyword_matrix.dimensions[dimension]
            matched_keywords = score_info.get('matched_keywords', {})
            
            for keyword, contribution in matched_keywords.items():
                if keyword in dimension_keywords:
                    keyword_info = dimension_keywords[keyword]
                    
                    # æ›´æ–°ä½¿ç”¨ç»Ÿè®¡
                    keyword_info.usage_count += 1
                    keyword_info.total_score_contribution += contribution
                    keyword_info.last_updated = datetime.now().isoformat()
                    
                    # è®¡ç®—ç¨³å®šæ€§å› å­
                    stability_factor = self._calculate_stability_factor(keyword_info)
                    
                    # è®¡ç®—æ€§èƒ½å› å­
                    avg_contribution = keyword_info.total_score_contribution / keyword_info.usage_count
                    performance_factor = self._calculate_performance_factor(avg_contribution)
                    
                    # è‡ªé€‚åº”æƒé‡è°ƒæ•´
                    if keyword_info.usage_count < self.keyword_matrix.stabilization_threshold:
                        # å­¦ä¹ æœŸï¼šç§¯æè°ƒæ•´
                        adjustment = self.keyword_matrix.learning_rate * stability_factor * performance_factor
                        keyword_info.weight = max(0.1, min(2.0, keyword_info.weight + adjustment))
                    else:
                        # ç¨³å®šæœŸï¼šä¿å®ˆè°ƒæ•´
                        adjustment = self.keyword_matrix.learning_rate * 0.1 * performance_factor
                        keyword_info.weight = max(0.5, min(1.5, keyword_info.weight + adjustment))
                    
                    # æ›´æ–°ç¨³å®šæ€§åˆ†æ•°
                    keyword_info.stability_score = self._calculate_stability_score(keyword_info)

def _calculate_stability_factor(self, keyword_info: KeywordInfo) -> float:
    """è®¡ç®—ç¨³å®šæ€§å› å­"""
    usage_ratio = min(1.0, keyword_info.usage_count / self.keyword_matrix.stabilization_threshold)
    
    if keyword_info.usage_count < self.keyword_matrix.stabilization_threshold:
        return 1.0 + (self.keyword_matrix.learning_rate * usage_ratio)
    else:
        return 1.0 + (self.keyword_matrix.learning_rate * 0.1)

def _calculate_performance_factor(self, avg_contribution: float) -> float:
    """è®¡ç®—æ€§èƒ½å› å­"""
    if avg_contribution > 0.8:
        return 1.1  # é«˜æ€§èƒ½å…³é”®è¯
    elif avg_contribution < 0.3:
        return 0.9  # ä½æ€§èƒ½å…³é”®è¯
    else:
        return 1.0  # ä¸€èˆ¬æ€§èƒ½
```

### 3. ä¼˜åŒ–è¯„åˆ†å¼•æ“ (OptimizedScoringEngine)

#### æ‰¹é‡å¹¶è¡Œå¤„ç†å®ç°

```python
def batch_calculate_scores(self, user_message: str, memories: List[MemoryEntry], max_workers: int = 4) -> List[Tuple]:
    """æ‰¹é‡å¹¶è¡Œè®¡ç®—è¯„åˆ†"""
    import concurrent.futures
    import hashlib
    
    def calculate_single_score(memory):
        try:
            # ç”Ÿæˆç¼“å­˜é”®
            cache_key = self._generate_cache_key(user_message, memory.id)
            
            # æ£€æŸ¥ç¼“å­˜
            if cache_key in self.score_cache:
                self.cache_hits += 1
                return memory.id, self.score_cache[cache_key], {'cached': True}
            
            # è®¡ç®—æ–°è¯„åˆ†
            start_time = time.time()
            score, details = self.calculate_memory_score(user_message, memory)
            end_time = time.time()
            
            # æ›´æ–°æ€§èƒ½ç»Ÿè®¡
            self.total_calculations += 1
            self.total_calculation_time += (end_time - start_time)
            
            # æ›´æ–°ç¼“å­˜
            self.score_cache[cache_key] = score
            if len(self.score_cache) > self.max_cache_size:
                self._cleanup_cache()
            
            details['cached'] = False
            details['calculation_time'] = end_time - start_time
            
            return memory.id, score, details
            
        except Exception as e:
            self.calculation_errors += 1
            return memory.id, 0.0, {'error': str(e)}
    
    # å¹¶è¡Œå¤„ç†
    start_time = time.time()
    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
        results = list(executor.map(calculate_single_score, memories))
    
    # æ›´æ–°æ‰¹é‡å¤„ç†ç»Ÿè®¡
    processing_time = time.time() - start_time
    self.batch_processing_times.append(processing_time)
    
    return results

def _generate_cache_key(self, user_message: str, memory_id: str) -> str:
    """ç”Ÿæˆç¼“å­˜é”®"""
    import hashlib
    content = f"{user_message}:{memory_id}"
    return hashlib.md5(content.encode()).hexdigest()

def _cleanup_cache(self):
    """æ¸…ç†ç¼“å­˜ï¼Œä¿ç•™æœ€è¿‘ä½¿ç”¨çš„æ¡ç›®"""
    if len(self.score_cache) > self.max_cache_size:
        # ç®€å•çš„LRUç­–ç•¥ï¼šåˆ é™¤æœ€è€çš„ä¸€åŠæ¡ç›®
        cache_items = list(self.score_cache.items())
        keep_count = self.max_cache_size // 2
        self.score_cache = dict(cache_items[-keep_count:])
```

#### æ€§èƒ½ç›‘æ§å®ç°

```python
def get_performance_stats(self) -> Dict:
    """è·å–æ€§èƒ½ç»Ÿè®¡ä¿¡æ¯"""
    total_requests = self.cache_hits + self.total_calculations
    
    return {
        'cache_hit_rate': self.cache_hits / total_requests if total_requests > 0 else 0,
        'total_calculations': self.total_calculations,
        'cache_hits': self.cache_hits,
        'calculation_errors': self.calculation_errors,
        'avg_response_time': self.total_calculation_time / self.total_calculations if self.total_calculations > 0 else 0,
        'avg_batch_time': sum(self.batch_processing_times) / len(self.batch_processing_times) if self.batch_processing_times else 0,
        'cache_size': len(self.score_cache),
        'max_cache_size': self.max_cache_size
    }
```

### 4. System Promptç”Ÿæˆå™¨ (SystemPromptGenerator)

#### æ ¸å¿ƒç”Ÿæˆé€»è¾‘

```python
def generate_system_prompt(self, user_message: str, team_name: str, mode: str = "hybrid", **kwargs) -> Dict[str, Any]:
    """ç”Ÿæˆç³»ç»Ÿæç¤ºè¯"""
    try:
        # 1. å‚æ•°éªŒè¯å’Œé¢„å¤„ç†
        available_teams = self.get_available_teams()
        if team_name not in available_teams:
            return {
                "success": False,
                "error": f"å›¢é˜Ÿ '{team_name}' ä¸å­˜åœ¨ã€‚å¯ç”¨å›¢é˜Ÿ: {available_teams}",
                "available_teams": available_teams
            }
        
        # 2. è°ƒç”¨å›¢é˜Ÿä¸Šä¸‹æ–‡å‘½ä»¤ç”Ÿæˆä¸Šä¸‹æ–‡
        result = self.context_command.execute(
            team_name=team_name,
            action="generate",
            mode=mode,
            stages=kwargs.get('stages', 'all'),
            memory_types=kwargs.get('memory_types', 'all'),
            output_format="json",
            save_results=kwargs.get('save_results', False),
            project_scope=kwargs.get('project_scope'),
            memory_importance=kwargs.get('memory_importance', 2),
            max_memory_items=kwargs.get('max_memory_items', 50),
            tags_filter=kwargs.get('tags_filter'),
            user_message=user_message
        )
        
        if not result.success:
            return {
                "success": False,
                "error": f"ä¸Šä¸‹æ–‡ç”Ÿæˆå¤±è´¥: {result.error or result.message}",
                "team_name": team_name,
                "mode": mode
            }
        
        # 3. æå–å’Œå¤„ç†ç”Ÿæˆçš„å†…å®¹
        system_prompt = self._extract_system_prompt_content(result)
        
        # 4. ä¿å­˜ç»“æœ
        saved_file_path = self._save_system_prompt(
            system_prompt=system_prompt,
            team_name=team_name,
            mode=mode,
            user_message=user_message
        )
        
        # 5. æ„å»ºè¿”å›ç»“æœ
        generation_result = {
            "success": True,
            "system_prompt": system_prompt,
            "system_prompt_length": len(system_prompt),
            "team_name": team_name,
            "mode": mode,
            "user_message": user_message,
            "user_message_length": len(user_message),
            "saved_to": saved_file_path,
            "generation_metadata": {
                "stages": kwargs.get('stages', 'all'),
                "memory_types": kwargs.get('memory_types', 'all'),
                "project_scope": kwargs.get('project_scope'),
                "memory_importance": kwargs.get('memory_importance', 2),
                "max_memory_items": kwargs.get('max_memory_items', 50),
                "tags_filter": kwargs.get('tags_filter'),
                "learning_enabled": self._learning_enabled
            }
        }
        
        # 6. å­¦ä¹ æœºåˆ¶å¤„ç†
        matched_memories = self._extract_matched_memories(result)
        self._record_generation_session(team_name, user_message, generation_result, matched_memories)
        
        if self._learning_enabled and matched_memories:
            self._perform_lightweight_learning(team_name, user_message, matched_memories, kwargs.get('verbose', False))
        
        return generation_result
        
    except Exception as e:
        return {
            "success": False,
            "error": str(e),
            "team_name": team_name,
            "mode": mode,
            "user_message": user_message
        }
```

#### å­¦ä¹ æœºåˆ¶å®ç°

```python
def _perform_lightweight_learning(self, team_name: str, user_message: str, matched_memories: list, verbose: bool = False):
    """æ‰§è¡Œè½»é‡çº§å­¦ä¹ ï¼ˆä¸ç«‹å³æ›´æ–°æƒé‡ï¼Œä»…è®°å½•ç»Ÿè®¡ï¼‰"""
    try:
        scoring_engine_info = self._get_scoring_engine(team_name)
        if not scoring_engine_info:
            return
        
        scoring_engine = scoring_engine_info['engine']
        
        # åˆ›å»ºè™šæ‹Ÿè®°å¿†é¡¹ç›®ç”¨äºç»Ÿè®¡æ›´æ–°
        from src.scoring_self_evolution import MemoryItem
        
        mock_memories = []
        for i, memory_id in enumerate(matched_memories[:5]):  # é™åˆ¶æœ€å¤š5ä¸ª
            mock_memory = MemoryItem(
                id=memory_id,
                title=f"System Prompt Matched Memory {i+1}",
                content=f"Memory matched for: {user_message[:100]}",
                tags=["system_prompt", "matched"],
                project="system_prompt_generation",
                importance=3
            )
            mock_memories.append(mock_memory)
        
        if mock_memories:
            # æ‰§è¡Œè½»é‡çº§è¯„åˆ†ï¼ˆä¸»è¦ä¸ºäº†ç»Ÿè®¡æ›´æ–°ï¼‰
            results = scoring_engine.score_memory_items(user_message, mock_memories)
            
            # ä¿å­˜æ›´æ–°åçš„çŸ©é˜µ
            matrix_file = scoring_engine_info['matrix_file']
            scoring_engine.save_matrix(str(matrix_file))
            
            if verbose:
                print(f"ğŸ“ è½»é‡çº§å­¦ä¹ å®Œæˆ - æ›´æ–°äº†{len(matched_memories)}ä¸ªè®°å¿†çš„ç»Ÿè®¡ä¿¡æ¯")
                
    except Exception as e:
        if verbose:
            print(f"âš ï¸ è½»é‡çº§å­¦ä¹ å¤±è´¥: {e}")

def provide_usage_feedback(self, team_name: str, user_message: str, system_prompt_effectiveness: int, **kwargs) -> Dict[str, Any]:
    """æä¾›System Promptä½¿ç”¨æ•ˆæœåé¦ˆï¼Œè§¦å‘æ·±åº¦å­¦ä¹ """
    if not self._learning_enabled:
        return {"success": False, "message": "å­¦ä¹ æœºåˆ¶æœªå¯ç”¨"}
    
    try:
        scoring_engine_info = self._get_scoring_engine(team_name)
        if not scoring_engine_info:
            return {"success": False, "message": "è¯„åˆ†å¼•æ“ä¸å¯ç”¨"}
        
        scoring_engine = scoring_engine_info['engine']
        matched_memories = kwargs.get('matched_memories', [])
        comment = kwargs.get('comment', '')
        
        # ä¸ºæ¯ä¸ªåŒ¹é…çš„è®°å¿†æ·»åŠ åé¦ˆ
        feedback_count = 0
        if matched_memories:
            for memory_id in matched_memories:
                scoring_engine.add_user_feedback(
                    memory_id=memory_id,
                    query=user_message,
                    rating=system_prompt_effectiveness,
                    matched_keywords=[],
                    comment=f"System Prompt feedback: {comment}"
                )
                feedback_count += 1
        
        # ä¿å­˜å­¦ä¹ ç»“æœ
        matrix_file = scoring_engine_info['matrix_file']
        scoring_engine.save_matrix(str(matrix_file))
        
        return {
            "success": True,
            "message": f"åé¦ˆå·²è®°å½•ï¼Œæ›´æ–°äº†{feedback_count}ä¸ªè®°å¿†çš„å­¦ä¹ æ•°æ®",
            "feedback_count": feedback_count,
            "effectiveness_rating": system_prompt_effectiveness
        }
        
    except Exception as e:
        return {"success": False, "message": f"åé¦ˆå¤„ç†å¤±è´¥: {e}"}
```

### 5. ä¸ƒæ­¥æ¡†æ¶å¼•æ“ (SevenStageEngine)

#### æ¡†æ¶æ¨¡æ¿åŠ è½½æœºåˆ¶

```python
class SevenStageEngine:
    """ä¸ƒæ­¥æ¡†æ¶å¼•æ“"""
    
    def __init__(self, framework_path: Path):
        self.framework_path = framework_path
        self.stage_files = {
            "overview": "00_overview.md",
            "requirements": "01_requirements.md", 
            "business-model": "02_business_model.md",
            "solution": "03_solution.md",
            "structure": "04_structure.md",
            "tasks": "05_tasks.md",
            "common-tasks": "06_common_tasks.md",
            "constraints": "07_constraints.md"
        }
        
    def load_framework_content(self, stages: List[str]) -> Dict[str, str]:
        """åŠ è½½æ¡†æ¶å†…å®¹"""
        content = {}
        
        # å§‹ç»ˆåŒ…å«æ¦‚è¿°
        overview_content = self._load_stage_content("overview")
        if overview_content:
            content["overview"] = overview_content
        
        # æŒ‰é¡ºåºåŠ è½½æŒ‡å®šé˜¶æ®µ
        stage_order = ["requirements", "business-model", "solution", "structure", "tasks", "common-tasks", "constraints"]
        
        for stage in stage_order:
            if stage in stages:
                stage_content = self._load_stage_content(stage)
                if stage_content:
                    content[stage] = stage_content
        
        return content
    
    def _load_stage_content(self, stage: str) -> Optional[str]:
        """åŠ è½½å•ä¸ªé˜¶æ®µå†…å®¹"""
        if stage not in self.stage_files:
            return None
            
        stage_file = self.framework_path / self.stage_files[stage]
        if stage_file.exists():
            return stage_file.read_text(encoding='utf-8')
        return None
    
    def validate_stage_sequence(self, stages: List[str]) -> Dict[str, Any]:
        """éªŒè¯é˜¶æ®µåºåˆ—çš„å®Œæ•´æ€§å’Œé€»è¾‘æ€§"""
        stage_order = ["requirements", "business-model", "solution", "structure", "tasks", "common-tasks", "constraints"]
        
        # æ£€æŸ¥é˜¶æ®µé¡ºåº
        ordered_stages = [s for s in stage_order if s in stages]
        
        # æ£€æŸ¥å…³é”®ä¾èµ–
        validation_result = {
            "valid": True,
            "warnings": [],
            "errors": [],
            "suggested_order": ordered_stages
        }
        
        # éªŒè¯å…³é”®ä¾èµ–å…³ç³»
        if "solution" in stages and "requirements" not in stages:
            validation_result["warnings"].append("è§£å†³æ–¹æ¡ˆé˜¶æ®µå»ºè®®åŒ…å«éœ€æ±‚é”šå®šé˜¶æ®µ")
        
        if "structure" in stages and "solution" not in stages:
            validation_result["warnings"].append("ç»“æ„å®šä¹‰é˜¶æ®µå»ºè®®åŒ…å«è§£å†³æ–¹æ¡ˆé˜¶æ®µ")
        
        if "tasks" in stages and "structure" not in stages:
            validation_result["warnings"].append("ä»»åŠ¡ç¼–æ’é˜¶æ®µå»ºè®®åŒ…å«ç»“æ„å®šä¹‰é˜¶æ®µ")
        
        return validation_result
```

### 6. ç›®å½•ç®¡ç†å™¨ (DirectoryManager)

#### å›¢é˜Ÿå’Œé¡¹ç›®ç»“æ„ç®¡ç†

```python
class DirectoryManager:
    """ç›®å½•ç®¡ç†å™¨"""
    
    def __init__(self, base_path: Path):
        self.base_path = Path(base_path)
        self.teams_path = self.base_path / "teams"
        
    def create_team(self, team_name: str, description: str = "") -> Path:
        """åˆ›å»ºå›¢é˜Ÿç›®å½•ç»“æ„"""
        team_path = self.teams_path / team_name
        
        if team_path.exists():
            raise ValueError(f"å›¢é˜Ÿ '{team_name}' å·²å­˜åœ¨")
        
        # åˆ›å»ºå›¢é˜Ÿç›®å½•ç»“æ„
        directories = [
            team_path,
            team_path / "memory",
            team_path / "memory" / "episodic", 
            team_path / "context",
            team_path / "projects"
        ]
        
        for directory in directories:
            directory.mkdir(parents=True, exist_ok=True)
        
        # åˆ›å»ºåˆå§‹æ–‡ä»¶
        self._create_initial_memory_files(team_path)
        self._create_team_metadata(team_path, team_name, description)
        
        return team_path
    
    def create_project(self, team_name: str, project_name: str, description: str = "") -> Path:
        """åˆ›å»ºé¡¹ç›®ç›®å½•ç»“æ„"""
        team_path = self.get_team_path(team_name)
        if not team_path.exists():
            raise ValueError(f"å›¢é˜Ÿ '{team_name}' ä¸å­˜åœ¨")
        
        project_path = team_path / "projects" / project_name
        
        if project_path.exists():
            raise ValueError(f"é¡¹ç›® '{project_name}' å·²å­˜åœ¨")
        
        # åˆ›å»ºé¡¹ç›®ç›®å½•ç»“æ„
        directories = [
            project_path,
            project_path / "memory",
            project_path / "memory" / "episodic",
            project_path / "context"
        ]
        
        for directory in directories:
            directory.mkdir(parents=True, exist_ok=True)
            
        # åˆ›å»ºåˆå§‹æ–‡ä»¶
        self._create_initial_memory_files(project_path)
        self._create_project_metadata(project_path, project_name, description)
        
        return project_path
    
    def _create_initial_memory_files(self, base_path: Path):
        """åˆ›å»ºåˆå§‹è®°å¿†æ–‡ä»¶"""
        memory_path = base_path / "memory"
        
        # åˆ›å»ºç¨‹åºæ€§è®°å¿†æ–‡ä»¶
        procedural_file = memory_path / "procedural.md"
        if not procedural_file.exists():
            procedural_content = f"""# å›¢é˜Ÿè®°å¿†ï¼š{base_path.name.title()}

## å…ƒæ•°æ®
- **å›¢é˜Ÿ**: {base_path.name}
- **åˆ›å»ºæ—¶é—´**: {datetime.now().isoformat()}
- **æœ€åæ›´æ–°**: {datetime.now().isoformat()}
- **è®°å¿†ç±»å‹**: procedural

## è®°å¿†æ¡ç›®

<!-- åœ¨è¿™é‡Œæ·»åŠ ç¨‹åºæ€§è®°å¿†æ¡ç›® -->
"""
            procedural_file.write_text(procedural_content, encoding='utf-8')
        
        # åˆ›å»ºå£°æ˜æ€§è®°å¿†æ–‡ä»¶
        declarative_file = memory_path / "declarative.md"
        if not declarative_file.exists():
            declarative_content = f"""# å›¢é˜Ÿå£°æ˜æ€§è®°å¿†ï¼š{base_path.name.title()}

## å…ƒæ•°æ®
- **å›¢é˜Ÿ**: {base_path.name}  
- **åˆ›å»ºæ—¶é—´**: {datetime.now().isoformat()}
- **æœ€åæ›´æ–°**: {datetime.now().isoformat()}
- **è®°å¿†ç±»å‹**: declarative

## è®°å¿†æ¡ç›®

<!-- åœ¨è¿™é‡Œæ·»åŠ å£°æ˜æ€§è®°å¿†æ¡ç›® -->
"""
            declarative_file.write_text(declarative_content, encoding='utf-8')
    
    def get_memory_path(self, team_name: str, memory_type: str, project_name: str = None) -> Path:
        """è·å–è®°å¿†æ–‡ä»¶è·¯å¾„"""
        if project_name:
            base_path = self.teams_path / team_name / "projects" / project_name
        else:
            base_path = self.teams_path / team_name
            
        if memory_type == "episodic":
            return base_path / "memory" / "episodic"
        else:
            return base_path / "memory" / f"{memory_type}.md"
```

## ğŸ”„ æ•°æ®æµå®ç°

### è®°å¿†æ£€ç´¢æ•°æ®æµ

```python
def _load_team_memories(self, team_path: Path, config: ContextGenerationConfig) -> List[MemoryEntry]:
    """åŠ è½½å›¢é˜Ÿæˆ–é¡¹ç›®è®°å¿†"""
    memories = []
    
    # ç¡®å®šè¦åŠ è½½çš„è®°å¿†ç±»å‹
    memory_types_to_load = config.include_memory_types
    if MemoryType.ALL in memory_types_to_load:
        memory_types_to_load = [MemoryType.DECLARATIVE, MemoryType.PROCEDURAL, MemoryType.EPISODIC]
    
    # ä¼˜å…ˆåŠ è½½é¡¹ç›®çº§åˆ«çš„è®°å¿†
    if config.project_name:
        project_path = team_path / "projects" / config.project_name
        if project_path.exists():
            project_memories = self._load_memories_from_path(project_path, memory_types_to_load, f"project:{config.project_name}")
            memories.extend(project_memories)
    
    # åŠ è½½å›¢é˜Ÿçº§åˆ«çš„è®°å¿†
    if config.include_team_memories or not config.project_name:
        team_memories = self._load_memories_from_path(team_path, memory_types_to_load, "team")
        memories.extend(team_memories)
    
    # å»é‡ï¼šåŸºäºè®°å¿†IDå»é™¤é‡å¤é¡¹ï¼Œä¿ç•™ç¬¬ä¸€ä¸ªï¼ˆé¡¹ç›®è®°å¿†ä¼˜å…ˆï¼‰
    seen_ids = set()
    unique_memories = []
    for memory in memories:
        if memory.id not in seen_ids:
            seen_ids.add(memory.id)
            unique_memories.append(memory)
    
    # åº”ç”¨è¿‡æ»¤å™¨
    filtered_memories = self._apply_memory_filters(unique_memories, config)
    
    # æ’åºï¼šæŒ‰é‡è¦æ€§å’Œæ—¶é—´æ’åº
    filtered_memories.sort(key=lambda m: (m.importance, m.timestamp), reverse=True)
    
    # é™åˆ¶æ•°é‡
    return filtered_memories[:config.max_memory_items]
```

### ä¸Šä¸‹æ–‡ç»„è£…æ•°æ®æµ

```python
def _generate_hybrid_context(self, config: ContextGenerationConfig, team_path: Path, user_message: str = None) -> GeneratedContext:
    """ç”Ÿæˆæ··åˆæ¨¡å¼ä¸Šä¸‹æ–‡ï¼ˆè®°å¿†+æ¡†æ¶ï¼‰"""
    memories = self._load_team_memories(team_path, config)
    
    content_sections = []
    used_memory_ids = set()
    
    # 1. æ·»åŠ æ··åˆæ¨¡å¼æŒ‡å¯¼æç¤º
    content_sections.extend([
        "å…ˆç†è§£è®°å¿†çš„å†…å®¹ï¼Œå†åŸºäºä¸ƒæ­¥æ¡†æ¶ç»“åˆuser_messageç”Ÿæˆå…·ä½“çš„ç»“æ„åŒ–æç¤ºè¯",
        "",
        "---",
        ""
    ])
    
    # 2. æ™ºèƒ½é€‰æ‹©å’Œæ·»åŠ ç›¸å…³è®°å¿†
    if memories and user_message:
        relevant_memories = self._find_relevant_memories_by_message(memories, user_message)
        if relevant_memories:
            top_memories = relevant_memories[:5]  # é™åˆ¶æœ€å¤š5ä¸ªæœ€ç›¸å…³çš„è®°å¿†
            for memory in top_memories:
                content_sections.extend([
                    f"#å›¢é˜Ÿè®°å¿†",
                    f"### {memory.id}",
                    f"**Project:** {memory.project}",
                    f"**Importance:** {'â­' * memory.importance}",
                    f"**Tags:** {', '.join(memory.tags)}",
                    "",
                    memory.content,
                    "",
                    "---",
                    ""
                ])
                used_memory_ids.add(memory.id)
    
    # 3. åŠ è½½å’Œç»„è£…ä¸ƒé˜¶æ®µæ¡†æ¶
    content_sections.extend([
        "# ä¸ƒæ­¥æ¡†æ¶æ¨¡æ¿å†…å®¹",
        "",
        ""
    ])
    
    included_stages = []
    for stage in config.include_framework_stages:
        stage_content = self._load_framework_stage(stage)
        if stage_content:
            included_stages.append(stage)
            content_sections.extend([stage_content, ""])
            
            # åŠ è½½é¡¹ç›®æˆ–å›¢é˜Ÿè‡ªå®šä¹‰ä¸Šä¸‹æ–‡
            context_content = self._load_context_file(team_path, stage, config)
            if context_content and context_content.strip():
                content_sections.extend([context_content, ""])
            
            content_sections.extend(["---", ""])
    
    return GeneratedContext(
        team_name=config.team_name,
        mode=config.mode,
        content="\n".join(content_sections),
        source_memories=list(used_memory_ids),
        framework_stages=included_stages,
        metadata={
            'memory_count': len(used_memory_ids),
            'total_memories_available': len(memories),
            'framework_stages_count': len(included_stages),
            'hybrid_mode': True
        }
    )
```

## âš¡ æ€§èƒ½ä¼˜åŒ–å®ç°

### ç¼“å­˜æœºåˆ¶

```python
class CacheManager:
    """ç¼“å­˜ç®¡ç†å™¨"""
    
    def __init__(self, max_size: int = 1000):
        self.max_size = max_size
        self.cache = {}
        self.access_times = {}
        self.hit_count = 0
        self.miss_count = 0
    
    def get(self, key: str) -> Optional[Any]:
        """è·å–ç¼“å­˜å€¼"""
        if key in self.cache:
            self.access_times[key] = time.time()
            self.hit_count += 1
            return self.cache[key]
        else:
            self.miss_count += 1
            return None
    
    def put(self, key: str, value: Any):
        """å­˜å‚¨ç¼“å­˜å€¼"""
        if len(self.cache) >= self.max_size:
            self._evict_lru()
        
        self.cache[key] = value
        self.access_times[key] = time.time()
    
    def _evict_lru(self):
        """LRUæ·˜æ±°ç­–ç•¥"""
        if not self.access_times:
            return
            
        # æ‰¾åˆ°æœ€å°‘æœ€è¿‘ä½¿ç”¨çš„key
        lru_key = min(self.access_times.keys(), key=lambda k: self.access_times[k])
        
        # åˆ é™¤
        del self.cache[lru_key]
        del self.access_times[lru_key]
    
    def get_stats(self) -> Dict:
        """è·å–ç¼“å­˜ç»Ÿè®¡"""
        total_requests = self.hit_count + self.miss_count
        return {
            'hit_rate': self.hit_count / total_requests if total_requests > 0 else 0,
            'hit_count': self.hit_count,
            'miss_count': self.miss_count,
            'cache_size': len(self.cache),
            'max_size': self.max_size
        }
```

### å¹¶å‘å¤„ç†

```python
import asyncio
import concurrent.futures
from typing import Awaitable

async def async_batch_process_memories(memories: List[MemoryEntry], user_message: str, max_concurrent: int = 10) -> List[Tuple]:
    """å¼‚æ­¥æ‰¹é‡å¤„ç†è®°å¿†è¯„åˆ†"""
    
    semaphore = asyncio.Semaphore(max_concurrent)
    
    async def process_single_memory(memory: MemoryEntry) -> Tuple:
        async with semaphore:
            # åœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡ŒCPUå¯†é›†å‹çš„è¯„åˆ†è®¡ç®—
            loop = asyncio.get_event_loop()
            with concurrent.futures.ThreadPoolExecutor() as executor:
                future = executor.submit(calculate_memory_score, user_message, memory)
                score, details = await loop.run_in_executor(None, future.result)
                return memory.id, score, details
    
    # åˆ›å»ºæ‰€æœ‰ä»»åŠ¡
    tasks = [process_single_memory(memory) for memory in memories]
    
    # å¹¶å‘æ‰§è¡Œæ‰€æœ‰ä»»åŠ¡
    results = await asyncio.gather(*tasks, return_exceptions=True)
    
    # å¤„ç†å¼‚å¸¸ç»“æœ
    clean_results = []
    for result in results:
        if isinstance(result, Exception):
            print(f"å¤„ç†è®°å¿†æ—¶å‡ºé”™: {result}")
        else:
            clean_results.append(result)
    
    return clean_results
```

## ğŸ”’ é”™è¯¯å¤„ç†å®ç°

### å¼‚å¸¸å±‚æ¬¡ç»“æ„

```python
class ContextManagementError(Exception):
    """ä¸Šä¸‹æ–‡ç®¡ç†åŸºç¡€å¼‚å¸¸"""
    pass

class TeamNotFoundError(ContextManagementError):
    """å›¢é˜Ÿä¸å­˜åœ¨å¼‚å¸¸"""
    def __init__(self, team_name: str, available_teams: List[str]):
        self.team_name = team_name
        self.available_teams = available_teams
        super().__init__(f"å›¢é˜Ÿ '{team_name}' ä¸å­˜åœ¨ã€‚å¯ç”¨å›¢é˜Ÿ: {available_teams}")

class MemoryLoadError(ContextManagementError):
    """è®°å¿†åŠ è½½å¼‚å¸¸"""
    def __init__(self, memory_path: str, cause: Exception):
        self.memory_path = memory_path
        self.cause = cause
        super().__init__(f"åŠ è½½è®°å¿†æ–‡ä»¶ '{memory_path}' å¤±è´¥: {cause}")

class ScoringEngineError(ContextManagementError):
    """è¯„åˆ†å¼•æ“å¼‚å¸¸"""
    pass

class APIConnectionError(ContextManagementError):
    """APIè¿æ¥å¼‚å¸¸"""
    def __init__(self, api_name: str, cause: Exception):
        self.api_name = api_name
        self.cause = cause
        super().__init__(f"{api_name} APIè°ƒç”¨å¤±è´¥: {cause}")
```

### é”™è¯¯å¤„ç†è£…é¥°å™¨

```python
def handle_context_errors(func):
    """ä¸Šä¸‹æ–‡å¤„ç†é”™è¯¯å¤„ç†è£…é¥°å™¨"""
    def wrapper(*args, **kwargs):
        try:
            return func(*args, **kwargs)
        except TeamNotFoundError as e:
            return {
                "success": False,
                "error_type": "team_not_found",
                "error": str(e),
                "available_teams": e.available_teams
            }
        except MemoryLoadError as e:
            return {
                "success": False,
                "error_type": "memory_load_error", 
                "error": str(e),
                "memory_path": e.memory_path
            }
        except APIConnectionError as e:
            return {
                "success": False,
                "error_type": "api_connection_error",
                "error": str(e),
                "api_name": e.api_name
            }
        except Exception as e:
            return {
                "success": False,
                "error_type": "unknown_error",
                "error": str(e)
            }
    return wrapper
```

è¿™äº›å®ç°ç»†èŠ‚å±•ç¤ºäº†ç³»ç»Ÿå„ä¸ªæ ¸å¿ƒæ¨¡å—çš„å…·ä½“å®ç°æ–¹å¼ï¼ŒåŒ…æ‹¬æ•°æ®ç»“æ„è®¾è®¡ã€ç®—æ³•å®ç°ã€æ€§èƒ½ä¼˜åŒ–ç­–ç•¥å’Œé”™è¯¯å¤„ç†æœºåˆ¶ï¼Œä¸ºç†è§£å’Œç»´æŠ¤ç³»ç»Ÿæä¾›äº†è¯¦ç»†çš„æŠ€æœ¯å‚è€ƒã€‚