#!/usr/bin/env python3
"""
è®°å¿†é¡¹ç›®æ ‡ç­¾è´¨é‡åˆ†æå·¥å…·

åŸºäºæ ‡ç­¾ç­–ç•¥æŒ‡å—ï¼Œæä¾›æ ‡ç­¾è´¨é‡è¯„ä¼°ã€ä¼˜åŒ–å»ºè®®å’Œæ‰¹é‡åˆ†æåŠŸèƒ½
"""

import re
import sys
import json
from pathlib import Path
from typing import List, Dict, Tuple, Optional
from dataclasses import dataclass
from collections import Counter

@dataclass
class MemoryEntry:
    """è®°å¿†æ¡ç›®æ•°æ®ç»“æ„"""
    id: str
    content: str
    tags: List[str]
    project: str = 'general'
    importance: int = 3
    file_path: str = ''

class TagAnalyzer:
    """æ ‡ç­¾è´¨é‡åˆ†æå™¨"""
    
    def __init__(self):
        self.load_tag_dictionaries()
    
    def load_tag_dictionaries(self):
        """åŠ è½½æ ‡ç­¾è¯å…¸"""
        self.core_business_tags = {
            'workflow', 'solution', 'rule', 'step', 'api', 'data', 'model', 
            'validation', 'creation', 'enhancement', 'optimization', 
            'integration', 'reference', 'authentication', 'authorization'
        }
        
        self.tech_stack_tags = {
            'rest-api', 'database', 'controller', 'service', 'repository', 
            'entity', 'dto', 'json', 'http', 'sql', 'nosql', 'cache', 
            'microservice', 'spring-boot'
        }
        
        self.action_tags = {
            'create', 'update', 'delete', 'validate', 'enhance', 'optimize', 
            'fix', 'implement', 'design', 'configure', 'deploy', 'test'
        }
        
        self.concept_combination_patterns = [
            r'.*-as-.*', r'.*-step.*', r'.*-validation', r'.*-enhancement',
            r'.*-processing', r'.*-routing', r'.*-integration'
        ]
        
        self.architecture_tags = {
            'architecture', 'design', 'microservice', 'scalability',
            'inheritance', 'polymorphism'
        }
    
    def analyze_memory_file(self, file_path: Path) -> Dict:
        """åˆ†æè®°å¿†æ–‡ä»¶çš„æ ‡ç­¾è´¨é‡"""
        memories = self.load_memories_from_file(file_path)
        results = {
            'file_path': str(file_path),
            'total_memories': len(memories),
            'memories': [],
            'overall_score': 0,
            'recommendations': []
        }
        
        total_score = 0
        for memory in memories:
            memory_analysis = self.analyze_memory_tags(memory)
            results['memories'].append(memory_analysis)
            total_score += memory_analysis['score']
        
        if memories:
            results['overall_score'] = total_score / len(memories)
            
        # ç”Ÿæˆæ•´ä½“å»ºè®®
        results['recommendations'] = self.generate_file_recommendations(results)
        
        return results
    
    def load_memories_from_file(self, file_path: Path) -> List[MemoryEntry]:
        """ä»æ–‡ä»¶åŠ è½½è®°å¿†æ¡ç›®"""
        if not file_path.exists():
            return []
        
        content = file_path.read_text(encoding='utf-8')
        memories = []
        
        # åŒ¹é…è®°å¿†æ¡ç›®
        memory_pattern = re.compile(
            r'### è®°å¿†é¡¹ç›® #(\w+)\n(.*?)(?=### è®°å¿†é¡¹ç›® #|\Z)',
            re.MULTILINE | re.DOTALL
        )
        
        matches = memory_pattern.findall(content)
        for entry_id, entry_content in matches:
            memory = self.parse_memory_entry(entry_id, entry_content, str(file_path))
            if memory:
                memories.append(memory)
        
        return memories
    
    def parse_memory_entry(self, entry_id: str, entry_content: str, file_path: str) -> Optional[MemoryEntry]:
        """è§£æå•ä¸ªè®°å¿†æ¡ç›®"""
        metadata_pattern = re.compile(r'- \*\*([^*]+)\*\*:\s*(.+?)(?=\n- \*\*|\Z)', re.DOTALL)
        metadata_matches = metadata_pattern.findall(entry_content)
        
        entry_data = {
            'id': entry_id,
            'file_path': file_path,
            'tags': [],
            'content': '',
            'project': 'general',
            'importance': 3
        }
        
        for key, value in metadata_matches:
            key = key.strip()
            value = value.strip()
            
            if key == 'å†…å®¹':
                entry_data['content'] = value
            elif key == 'æ ‡ç­¾':
                if ',' in value:
                    tags = [tag.strip().lstrip('#') for tag in value.split(',') if tag.strip()]
                else:
                    tags = [tag.strip().lstrip('#') for tag in value.split() if tag.strip()]
                entry_data['tags'] = tags
            elif key == 'é¡¹ç›®':
                entry_data['project'] = value
            elif key == 'é‡è¦æ€§':
                entry_data['importance'] = value.count('â­')
        
        if not entry_data['content']:
            return None
        
        return MemoryEntry(**entry_data)
    
    def analyze_memory_tags(self, memory: MemoryEntry) -> Dict:
        """åˆ†æå•ä¸ªè®°å¿†çš„æ ‡ç­¾è´¨é‡"""
        analysis = {
            'id': memory.id,
            'tag_count': len(memory.tags),
            'tags': memory.tags,
            'score': 0,
            'breakdown': {},
            'issues': [],
            'suggestions': []
        }
        
        # 1. æ ‡ç­¾æ•°é‡æ£€æŸ¥ (20åˆ†)
        tag_count_score = self.check_tag_count(memory.tags)
        analysis['breakdown']['tag_count'] = tag_count_score
        analysis['score'] += tag_count_score
        
        if tag_count_score < 15:
            if len(memory.tags) < 8:
                analysis['issues'].append(f"æ ‡ç­¾æ•°é‡è¿‡å°‘ ({len(memory.tags)}ä¸ª)ï¼Œå»ºè®®8-15ä¸ª")
                analysis['suggestions'].append("å¢åŠ æ›´å¤šæè¿°æ€§æ ‡ç­¾")
            else:
                analysis['issues'].append(f"æ ‡ç­¾æ•°é‡è¿‡å¤š ({len(memory.tags)}ä¸ª)ï¼Œå»ºè®®8-15ä¸ª")
                analysis['suggestions'].append("åˆ å‡å†—ä½™æ ‡ç­¾")
        
        # 2. åˆ†å±‚æ ‡ç­¾æ£€æŸ¥ (30åˆ†)
        layer_score = self.check_tag_layers(memory.tags)
        analysis['breakdown']['layer_distribution'] = layer_score
        analysis['score'] += sum(layer_score.values())
        
        if layer_score['core_function'] < 10:
            analysis['issues'].append("ç¼ºå°‘æ ¸å¿ƒåŠŸèƒ½æ ‡ç­¾")
            analysis['suggestions'].append("æ·»åŠ ç›´æ¥æè¿°è§£å†³é—®é¢˜çš„æ ‡ç­¾")
        
        if layer_score['tech_implementation'] < 5:
            analysis['issues'].append("ç¼ºå°‘æŠ€æœ¯å®ç°æ ‡ç­¾")
            analysis['suggestions'].append("æ·»åŠ æŠ€æœ¯æ ˆç›¸å…³æ ‡ç­¾")
        
        # 3. å…³é”®è¯è¦†ç›–æ£€æŸ¥ (25åˆ†)
        coverage_score = self.check_keyword_coverage(memory)
        analysis['breakdown']['keyword_coverage'] = coverage_score
        analysis['score'] += coverage_score
        
        if coverage_score < 15:
            analysis['issues'].append("æ ‡ç­¾ä¸å†…å®¹å…³é”®è¯è¦†ç›–åº¦ä½")
            analysis['suggestions'].append("åˆ†æå†…å®¹å…³é”®è¯ï¼Œæ·»åŠ ç›¸å…³æ ‡ç­¾")
        
        # 4. å‘½åè§„èŒƒæ£€æŸ¥ (25åˆ†)
        naming_score = self.check_naming_conventions(memory.tags)
        analysis['breakdown']['naming_conventions'] = naming_score
        analysis['score'] += naming_score
        
        if naming_score < 20:
            analysis['issues'].append("æ ‡ç­¾å‘½åä¸ç¬¦åˆè§„èŒƒ")
            analysis['suggestions'].append("ä½¿ç”¨è¿å­—ç¬¦åˆ†éš”ï¼Œé¿å…ä¸‹åˆ’çº¿å’Œé©¼å³°å‘½å")
        
        # ç”Ÿæˆå…·ä½“çš„æ ‡ç­¾å»ºè®®
        tag_suggestions = self.suggest_tags_for_memory(memory)
        if tag_suggestions:
            analysis['suggested_tags'] = tag_suggestions
        
        return analysis
    
    def check_tag_count(self, tags: List[str]) -> int:
        """æ£€æŸ¥æ ‡ç­¾æ•°é‡å¾—åˆ†"""
        count = len(tags)
        if 8 <= count <= 15:
            return 20
        elif 5 <= count < 8 or 15 < count <= 20:
            return 15
        else:
            return 10
    
    def check_tag_layers(self, tags: List[str]) -> Dict[str, int]:
        """æ£€æŸ¥æ ‡ç­¾åˆ†å±‚åˆ†å¸ƒ"""
        scores = {
            'core_function': 0,
            'tech_implementation': 0,
            'concept_combination': 0,
            'architecture_design': 0
        }
        
        # æ ¸å¿ƒåŠŸèƒ½æ ‡ç­¾æ£€æŸ¥
        core_count = sum(1 for tag in tags if tag in self.core_business_tags or tag in self.action_tags)
        if core_count >= 3:
            scores['core_function'] = 15
        elif core_count >= 2:
            scores['core_function'] = 10
        else:
            scores['core_function'] = 5
        
        # æŠ€æœ¯å®ç°æ ‡ç­¾æ£€æŸ¥
        tech_count = sum(1 for tag in tags if tag in self.tech_stack_tags)
        if tech_count >= 2:
            scores['tech_implementation'] = 8
        elif tech_count >= 1:
            scores['tech_implementation'] = 5
        else:
            scores['tech_implementation'] = 2
        
        # æ¦‚å¿µç»„åˆæ ‡ç­¾æ£€æŸ¥
        concept_count = sum(1 for tag in tags 
                           if any(re.match(pattern, tag) for pattern in self.concept_combination_patterns))
        if concept_count >= 2:
            scores['concept_combination'] = 7
        elif concept_count >= 1:
            scores['concept_combination'] = 4
        else:
            scores['concept_combination'] = 1
        
        # æ¶æ„è®¾è®¡æ ‡ç­¾æ£€æŸ¥
        arch_count = sum(1 for tag in tags if tag in self.architecture_tags)
        if arch_count <= 2 and arch_count > 0:
            scores['architecture_design'] = 5
        elif arch_count > 2:
            scores['architecture_design'] = 2  # å¤ªå¤šæ¶æ„æ ‡ç­¾
        else:
            scores['architecture_design'] = 3  # æ²¡æœ‰æ¶æ„æ ‡ç­¾ä¹Ÿå¯ä»¥
        
        return scores
    
    def check_keyword_coverage(self, memory: MemoryEntry) -> int:
        """æ£€æŸ¥å…³é”®è¯è¦†ç›–åº¦"""
        content_words = set(re.findall(r'\b[a-z]+\b', memory.content.lower()))
        tech_words = content_words & (self.core_business_tags | self.tech_stack_tags | self.action_tags)
        
        tag_words_lists = [tag.lower().replace('-', ' ').split() for tag in memory.tags]
        tag_words = {word for words in tag_words_lists for word in words}
        
        if not tech_words:
            return 15  # å¦‚æœå†…å®¹ä¸­æ²¡æœ‰æŠ€æœ¯è¯æ±‡ï¼Œç»™é»˜è®¤åˆ†
        
        coverage = len(tech_words & tag_words) / len(tech_words)
        return int(coverage * 25)
    
    def check_naming_conventions(self, tags: List[str]) -> int:
        """æ£€æŸ¥å‘½åè§„èŒƒ"""
        score = 25
        
        for tag in tags:
            # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨è¿å­—ç¬¦
            if '_' in tag:
                score -= 2  # ä½¿ç”¨ä¸‹åˆ’çº¿æ‰£åˆ†
            elif any(c.isupper() for c in tag):
                score -= 2  # ä½¿ç”¨å¤§å†™å­—æ¯æ‰£åˆ†
            elif len(tag.split('-')) > 4:
                score -= 1  # è¿‡é•¿çš„å¤åˆè¯æ‰£åˆ†
        
        return max(0, score)
    
    def suggest_tags_for_memory(self, memory: MemoryEntry) -> List[str]:
        """ä¸ºè®°å¿†å»ºè®®æ–°æ ‡ç­¾"""
        suggestions = []
        content_lower = memory.content.lower()
        existing_tags = set(tag.lower() for tag in memory.tags)
        
        # å»ºè®®æ ¸å¿ƒä¸šåŠ¡æ ‡ç­¾
        for tag in self.core_business_tags:
            if tag in content_lower and tag not in existing_tags:
                suggestions.append(tag)
        
        # å»ºè®®æŠ€æœ¯æ ˆæ ‡ç­¾
        for tag in self.tech_stack_tags:
            if tag.replace('-', ' ') in content_lower and tag not in existing_tags:
                suggestions.append(tag)
        
        # å»ºè®®åŠ¨ä½œæ ‡ç­¾
        for tag in self.action_tags:
            if tag in content_lower and tag not in existing_tags:
                suggestions.append(tag)
        
        # å»ºè®®æ¦‚å¿µç»„åˆæ ‡ç­¾
        concept_suggestions = self.suggest_concept_combinations(memory)
        suggestions.extend(concept_suggestions)
        
        return suggestions[:8]  # æœ€å¤šå»ºè®®8ä¸ªæ–°æ ‡ç­¾
    
    def suggest_concept_combinations(self, memory: MemoryEntry) -> List[str]:
        """å»ºè®®æ¦‚å¿µç»„åˆæ ‡ç­¾"""
        suggestions = []
        content_lower = memory.content.lower()
        
        # å¸¸è§æ¦‚å¿µç»„åˆæ¨¡å¼
        combinations = [
            ('solution', 'step', 'solution-as-step'),
            ('workflow', 'step', 'workflow-steps'),
            ('solution', 'reference', 'solution-reference'),
            ('step', 'validation', 'step-validation'),
            ('api', 'enhancement', 'api-enhancement'),
            ('workflow', 'creation', 'workflow-creation'),
            ('data', 'validation', 'data-validation'),
            ('error', 'handling', 'error-handling'),
            ('performance', 'optimization', 'performance-optimization')
        ]
        
        for word1, word2, combo_tag in combinations:
            if word1 in content_lower and word2 in content_lower:
                if combo_tag not in [tag.lower() for tag in memory.tags]:
                    suggestions.append(combo_tag)
        
        return suggestions
    
    def generate_file_recommendations(self, analysis_results: Dict) -> List[str]:
        """ç”Ÿæˆæ–‡ä»¶çº§åˆ«çš„å»ºè®®"""
        recommendations = []
        
        avg_score = analysis_results['overall_score']
        if avg_score < 70:
            recommendations.append(f"æ•´ä½“æ ‡ç­¾è´¨é‡éœ€è¦æ”¹è¿› (å¹³å‡åˆ†: {avg_score:.1f})")
        
        # ç»Ÿè®¡å¸¸è§é—®é¢˜
        all_issues = []
        for memory in analysis_results['memories']:
            all_issues.extend(memory['issues'])
        
        issue_counts = Counter(all_issues)
        for issue, count in issue_counts.most_common(3):
            if count > 1:
                recommendations.append(f"å¸¸è§é—®é¢˜: {issue} (å½±å“{count}ä¸ªè®°å¿†)")
        
        return recommendations

def main():
    """ä¸»å‡½æ•°"""
    if len(sys.argv) < 2:
        print("ä½¿ç”¨æ–¹æ³•: python memory_tag_analyzer.py <memory_file_or_directory>")
        print("ç¤ºä¾‹: python memory_tag_analyzer.py test_data/teams/engineering_team/memory/")
        return
    
    path = Path(sys.argv[1])
    analyzer = TagAnalyzer()
    
    if path.is_file():
        # åˆ†æå•ä¸ªæ–‡ä»¶
        results = analyzer.analyze_memory_file(path)
        print_analysis_results(results)
    elif path.is_dir():
        # åˆ†æç›®å½•ä¸‹çš„æ‰€æœ‰è®°å¿†æ–‡ä»¶
        memory_files = list(path.rglob("*.md"))
        memory_files = [f for f in memory_files if '/memory/' in str(f)]
        
        if not memory_files:
            print(f"åœ¨ {path} ä¸­æœªæ‰¾åˆ°è®°å¿†æ–‡ä»¶")
            return
        
        print(f"ğŸ” æ‰¾åˆ° {len(memory_files)} ä¸ªè®°å¿†æ–‡ä»¶")
        print("=" * 60)
        
        all_results = []
        for file_path in memory_files:
            results = analyzer.analyze_memory_file(file_path)
            all_results.append(results)
            print(f"\nğŸ“ {file_path.name}")
            print_analysis_results(results, brief=True)
        
        # ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š
        print("\n" + "=" * 60)
        print("ğŸ“Š æ±‡æ€»æŠ¥å‘Š")
        generate_summary_report(all_results)
    else:
        print(f"è·¯å¾„ä¸å­˜åœ¨: {path}")

def print_analysis_results(results: Dict, brief: bool = False):
    """æ‰“å°åˆ†æç»“æœ"""
    if brief:
        print(f"  å¹³å‡åˆ†: {results['overall_score']:.1f}/100")
        print(f"  è®°å¿†æ•°: {results['total_memories']}")
        if results['recommendations']:
            print(f"  ä¸»è¦é—®é¢˜: {results['recommendations'][0]}")
        return
    
    print(f"ğŸ“„ æ–‡ä»¶: {results['file_path']}")
    print(f"ğŸ“Š æ€»ä½“è¯„åˆ†: {results['overall_score']:.1f}/100")
    print(f"ğŸ§  è®°å¿†æ•°é‡: {results['total_memories']}")
    
    if results['recommendations']:
        print("\nğŸ’¡ æ–‡ä»¶çº§å»ºè®®:")
        for rec in results['recommendations']:
            print(f"  - {rec}")
    
    print(f"\nğŸ“‹ è¯¦ç»†åˆ†æ:")
    for memory in results['memories']:
        print(f"\n  è®°å¿† {memory['id']}:")
        print(f"    è¯„åˆ†: {memory['score']}/100")
        print(f"    æ ‡ç­¾æ•°: {memory['tag_count']}")
        print(f"    æ ‡ç­¾: {', '.join(memory['tags'][:5])}{'...' if len(memory['tags']) > 5 else ''}")
        
        if memory['issues']:
            print(f"    é—®é¢˜: {', '.join(memory['issues'][:2])}")
        
        if memory.get('suggested_tags'):
            print(f"    å»ºè®®æ–°å¢: {', '.join(memory['suggested_tags'][:3])}")

def generate_summary_report(all_results: List[Dict]):
    """ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š"""
    total_memories = sum(r['total_memories'] for r in all_results)
    avg_score = sum(r['overall_score'] * r['total_memories'] for r in all_results) / total_memories if total_memories > 0 else 0
    
    print(f"æ€»è®°å¿†æ•°: {total_memories}")
    print(f"å¹³å‡åˆ†: {avg_score:.1f}/100")
    
    # æ‰¾å‡ºå¾—åˆ†æœ€ä½çš„è®°å¿†
    all_memories = []
    for results in all_results:
        for memory in results['memories']:
            memory['file'] = results['file_path']
            all_memories.append(memory)
    
    all_memories.sort(key=lambda x: x['score'])
    
    print(f"\nğŸš¨ éœ€è¦ä¼˜å…ˆä¼˜åŒ–çš„è®°å¿† (è¯„åˆ† < 60):")
    low_score_memories = [m for m in all_memories if m['score'] < 60]
    for memory in low_score_memories[:5]:
        print(f"  {memory['id']} ({memory['score']}/100) - {Path(memory['file']).name}")

if __name__ == "__main__":
    main() 